{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajeetsen007/Classification_of-_Loan_Borrowers_Kaggle/blob/main/Classification_of_Loan_Borrowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eoKBfycgluJE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyxlsb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyxlsb\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "q2eaGOEBl2qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3fJTQXEpluJO"
      },
      "outputs": [],
      "source": [
        "train = pd.read_excel(\"training.xlsb\", engine='pyxlsb')\n",
        "test = pd.read_excel(\"test.xlsb\", engine='pyxlsb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OAKvOo6rluJP"
      },
      "outputs": [],
      "source": [
        "train = train.iloc[:89734,:]\n",
        "test = test.iloc[:38405,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wIKwYbVjluJP"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns',None)\n",
        "train.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O8BsYYDkluJQ"
      },
      "outputs": [],
      "source": [
        "train.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "e86lr4-OluJQ"
      },
      "outputs": [],
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z9JqzBcxluJR"
      },
      "outputs": [],
      "source": [
        "### Missing values\n",
        "print(\"Missing Values in Training df: \",train.isna().sum().sum())\n",
        "print(\"Missing Values in Test df: \",test.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pC5Dz6G7luJR"
      },
      "outputs": [],
      "source": [
        "### Categorical Values\n",
        "cat_var = [cols for cols in train.columns if train[cols].dtype == 'O']\n",
        "print(\"No. of categorical values :\", len(cat_var) ,'\\n', cat_var, '\\n')\n",
        "### Cardinality\n",
        "for cols in cat_var:\n",
        "    print(\"Column Name: \",cols, \"Unique Values: \",train[cols].unique(), \"Count of Unique Values: \", len(train[cols].unique()),\n",
        "          \"Count : \", train[cols].value_counts(), \"Percentage : \", train[cols].value_counts()/len(train[cols]),\n",
        "          sep = '\\n\\n', end = '\\n\\n')\n",
        "    print('-'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "scrolled": true,
        "id": "lmYAaSUhluJR"
      },
      "outputs": [],
      "source": [
        "### Rename the Known Columns\n",
        "new_cols = {'I':'Gender','K':'Region', 'M':'Job_Title', 'N':'Education', 'O':'Marital_Status',\n",
        "            'P':'Children', 'Q':'Property', 'S':'Employment_Status'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dztQtc7iluJS"
      },
      "outputs": [],
      "source": [
        "train.rename(columns = new_cols, inplace=True)\n",
        "test.rename(columns = new_cols, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GXdxyH7mluJS"
      },
      "outputs": [],
      "source": [
        "### Numerical Variables\n",
        "num_var = [cols for cols in train.columns if train[cols].dtype != 'O']\n",
        "print(\"No. of numerical values :\", len(num_var) ,'\\n', num_var, '\\n')\n",
        "### Distribution\n",
        "sns.pairplot(train)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7WaqExozluJS"
      },
      "outputs": [],
      "source": [
        "correlation = train.corr()\n",
        "correlation.style.background_gradient(cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Mt1ePjP-luJT"
      },
      "outputs": [],
      "source": [
        "for cols in num_var:\n",
        "    sns.boxplot(train[cols])\n",
        "    plt.title(cols)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwFi_POOluJT"
      },
      "outputs": [],
      "source": [
        "### Imbalance Data??\n",
        "print(train['MARKER'].value_counts())\n",
        "print(test['MARKER'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SbUrJpo5luJT"
      },
      "outputs": [],
      "source": [
        "### One-HOT Encoding\n",
        "X = pd.get_dummies(train, drop_first=True)\n",
        "y = pd.get_dummies(test, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b0JjUpvtluJT"
      },
      "outputs": [],
      "source": [
        "### Removing Columns to tackle Multi Collinearity (Corr > 0.6)\n",
        "X = X.drop(['A','D','F'],axis =1)\n",
        "y = y.drop(['A','D','F'],axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LkpXfet1luJU"
      },
      "outputs": [],
      "source": [
        "correlation = X.corr()\n",
        "correlation.style.background_gradient(cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "T3UttWfHluJU"
      },
      "outputs": [],
      "source": [
        "### Splitting the data - X,y - Train and Test\n",
        "X_train = X.drop(['ID','MARKER'], axis =1)\n",
        "y_train = X['MARKER']\n",
        "X_test = y.drop(['ID','MARKER'], axis =1)\n",
        "y_test = y['MARKER']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VjHqFmxrluJU"
      },
      "outputs": [],
      "source": [
        "### Scaling the data\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Dw8ZGbgluJU"
      },
      "outputs": [],
      "source": [
        "print(len(X_train))\n",
        "### Imbalance Data treatment\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "print(len(X_train_resampled))\n",
        "#print(X_train_resampled.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsXJk1WSluJU"
      },
      "outputs": [],
      "source": [
        "### Feature Selection\n",
        "#sel_from_model = SelectFromModel(Lasso(alpha=0.1,random_state=12))\n",
        "#sel_from_model.fit(X_train_resampled,y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY1mdmCRluJV"
      },
      "outputs": [],
      "source": [
        "'''selected_feat = X_train_resampled.columns[(sel_from_model.get_support())]\n",
        "\n",
        "# let's print some stats\n",
        "print('selected features: {}'.format(selected_feat))\n",
        "print('total features: {}'.format((X_train_resampled.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "print('features with coefficients shrank to zero: {}'.format(\n",
        "    np.sum(sel_from_model.estimator_.coef_ == 0)))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK7J-gLmluJV"
      },
      "outputs": [],
      "source": [
        "### Trying different data transformations\n",
        "\n",
        "colss = ([x for x in X_train_resampled.columns if X_train_resampled[x].dtype == float])\n",
        "print(X_train_resampled[colss].head())\n",
        "X_train_resampled[colss] = np.absolute(X_train_resampled[colss])\n",
        "print(X_train_resampled.head())\n",
        "#'''print(X_train_resampled[colss].head())\n",
        "#X_train_resampled[colss] = X_train_resampled[colss]**2\n",
        "#print(X_train_resampled[colss].head())'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZdXoSVF5luJV"
      },
      "outputs": [],
      "source": [
        "#### Applying Logistic Reg\n",
        "from  sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score,recall_score,f1_score,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lkuzLy0HluJV"
      },
      "outputs": [],
      "source": [
        "params = {\"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\"C\": [1.0, 1.5, 0.5],\n",
        "          \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\"max_iter\": [100, 150, 180]}\n",
        "\n",
        "log_model = LogisticRegression()\n",
        "model1 = GridSearchCV(estimator=log_model, param_grid=params,scoring = \"recall\", refit = True,verbose = 4, cv = 2)\n",
        "model1.fit(X_train_resampled,y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "kdZv_1WvluJW",
        "outputId": "1d6f3dba-499f-491f-921c-3b072e7119b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.5)"
            ],
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.5)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model1.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = GridSearchCV(estimator=log_model, param_grid=params,scoring = \"precision\", refit = True,verbose = 4, cv = 2)\n",
        "model2.fit(X_train_resampled,y_train_resampled)"
      ],
      "metadata": {
        "id": "-Kw1CV0NwszV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OhnfxQNdUEJB",
        "outputId": "3d22dfd7-db4e-4399-aa96-4ccf93dbd557"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=180, penalty='none')"
            ],
            "text/html": [
              "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=180, penalty=&#x27;none&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=180, penalty=&#x27;none&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = GridSearchCV(estimator=log_model, param_grid=params,scoring = \"f1\", refit = True,verbose = 4, cv = 2)\n",
        "model3.fit(X_train_resampled,y_train_resampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dMIaQysNKJFT",
        "outputId": "c8adf8ea-886a-425a-b4c7-6cc6cdb97dd0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 180 candidates, totalling 360 fits\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l1, solver=liblinear;, score=0.794 total time=  10.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l1, solver=liblinear;, score=0.846 total time=  11.8s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l1, solver=saga;, score=0.794 total time=   7.5s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l1, solver=saga;, score=0.846 total time=   5.9s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l2, solver=newton-cg;, score=0.794 total time=   3.7s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l2, solver=newton-cg;, score=0.845 total time=   3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l2, solver=lbfgs;, score=0.794 total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l2, solver=lbfgs;, score=0.845 total time=   1.7s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l2, solver=liblinear;, score=0.794 total time=   1.4s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l2, solver=liblinear;, score=0.845 total time=   1.7s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l2, solver=sag;, score=0.794 total time=   2.5s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l2, solver=sag;, score=0.845 total time=   2.3s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=l2, solver=saga;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=l2, solver=saga;, score=0.845 total time=   2.4s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=100, penalty=none, solver=newton-cg;, score=0.794 total time=  10.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=100, penalty=none, solver=newton-cg;, score=0.846 total time=  11.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=100, penalty=none, solver=lbfgs;, score=0.794 total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=100, penalty=none, solver=lbfgs;, score=0.845 total time=   1.6s\n",
            "[CV 1/2] END C=1.0, max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=100, penalty=none, solver=sag;, score=0.794 total time=   9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=100, penalty=none, solver=sag;, score=0.846 total time=   9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=100, penalty=none, solver=saga;, score=0.794 total time=   9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=100, penalty=none, solver=saga;, score=0.846 total time=   8.9s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l1, solver=liblinear;, score=0.794 total time=   9.8s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l1, solver=liblinear;, score=0.846 total time=  11.4s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l1, solver=saga;, score=0.794 total time=   7.8s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l1, solver=saga;, score=0.846 total time=   5.8s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l2, solver=newton-cg;, score=0.794 total time=   3.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l2, solver=newton-cg;, score=0.845 total time=   4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l2, solver=lbfgs;, score=0.794 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l2, solver=lbfgs;, score=0.845 total time=   2.5s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l2, solver=liblinear;, score=0.794 total time=   1.1s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l2, solver=liblinear;, score=0.845 total time=   1.3s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l2, solver=sag;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l2, solver=sag;, score=0.845 total time=   3.3s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=l2, solver=saga;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=l2, solver=saga;, score=0.845 total time=   2.5s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=150, penalty=none, solver=newton-cg;, score=0.794 total time=  10.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=150, penalty=none, solver=newton-cg;, score=0.846 total time=  11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=150, penalty=none, solver=lbfgs;, score=0.794 total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=150, penalty=none, solver=lbfgs;, score=0.846 total time=   2.4s\n",
            "[CV 1/2] END C=1.0, max_iter=150, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=150, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=150, penalty=none, solver=sag;, score=0.794 total time=  13.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=150, penalty=none, solver=sag;, score=0.846 total time=  13.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=150, penalty=none, solver=saga;, score=0.794 total time=  14.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=150, penalty=none, solver=saga;, score=0.846 total time=  15.1s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l1, solver=liblinear;, score=0.794 total time=  10.9s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l1, solver=liblinear;, score=0.846 total time=  12.2s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l1, solver=saga;, score=0.794 total time=   7.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l1, solver=saga;, score=0.846 total time=   5.9s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l2, solver=newton-cg;, score=0.794 total time=   3.6s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l2, solver=newton-cg;, score=0.845 total time=   3.6s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l2, solver=lbfgs;, score=0.794 total time=   2.7s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l2, solver=lbfgs;, score=0.845 total time=   4.2s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l2, solver=liblinear;, score=0.794 total time=   1.1s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l2, solver=liblinear;, score=0.845 total time=   1.3s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l2, solver=sag;, score=0.794 total time=   2.1s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l2, solver=sag;, score=0.845 total time=   2.4s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=l2, solver=saga;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=l2, solver=saga;, score=0.845 total time=   3.4s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=180, penalty=none, solver=newton-cg;, score=0.794 total time=   8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=180, penalty=none, solver=newton-cg;, score=0.846 total time=  11.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=180, penalty=none, solver=lbfgs;, score=0.794 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=180, penalty=none, solver=lbfgs;, score=0.846 total time=   3.2s\n",
            "[CV 1/2] END C=1.0, max_iter=180, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.0, max_iter=180, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=180, penalty=none, solver=sag;, score=0.794 total time=  16.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=180, penalty=none, solver=sag;, score=0.846 total time=  16.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.0, max_iter=180, penalty=none, solver=saga;, score=0.794 total time=  17.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.0, max_iter=180, penalty=none, solver=saga;, score=0.846 total time=  17.1s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.794 total time=  18.2s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.846 total time=  11.1s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l1, solver=saga;, score=0.794 total time=   9.8s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l1, solver=saga;, score=0.846 total time=   8.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l2, solver=newton-cg;, score=0.794 total time=   3.6s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l2, solver=newton-cg;, score=0.846 total time=   5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.795 total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.846 total time=   1.7s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.794 total time=   1.2s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.846 total time=   1.2s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l2, solver=sag;, score=0.794 total time=   2.3s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l2, solver=sag;, score=0.846 total time=   3.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=l2, solver=saga;, score=0.794 total time=   2.7s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=l2, solver=saga;, score=0.846 total time=   3.3s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.1s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=100, penalty=none, solver=newton-cg;, score=0.794 total time=  10.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=100, penalty=none, solver=newton-cg;, score=0.846 total time=  11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=100, penalty=none, solver=lbfgs;, score=0.794 total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=100, penalty=none, solver=lbfgs;, score=0.845 total time=   1.7s\n",
            "[CV 1/2] END C=1.5, max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=100, penalty=none, solver=sag;, score=0.794 total time=  10.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=100, penalty=none, solver=sag;, score=0.846 total time=  10.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=100, penalty=none, solver=saga;, score=0.794 total time=  10.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=100, penalty=none, solver=saga;, score=0.846 total time=  10.3s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l1, solver=liblinear;, score=0.794 total time=   9.2s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l1, solver=liblinear;, score=0.846 total time=  12.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l1, solver=saga;, score=0.794 total time=  10.7s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l1, solver=saga;, score=0.846 total time=   6.8s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l2, solver=newton-cg;, score=0.794 total time=   4.7s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l2, solver=newton-cg;, score=0.846 total time=   4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l2, solver=lbfgs;, score=0.794 total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l2, solver=lbfgs;, score=0.846 total time=   2.9s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l2, solver=liblinear;, score=0.794 total time=   1.6s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l2, solver=liblinear;, score=0.846 total time=   1.3s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l2, solver=sag;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l2, solver=sag;, score=0.846 total time=   2.6s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=l2, solver=saga;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=l2, solver=saga;, score=0.846 total time=   4.4s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=150, penalty=none, solver=newton-cg;, score=0.794 total time=   8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=150, penalty=none, solver=newton-cg;, score=0.846 total time=  11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=150, penalty=none, solver=lbfgs;, score=0.794 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=150, penalty=none, solver=lbfgs;, score=0.846 total time=   3.3s\n",
            "[CV 1/2] END C=1.5, max_iter=150, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=150, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=150, penalty=none, solver=sag;, score=0.794 total time=  13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=150, penalty=none, solver=sag;, score=0.846 total time=  13.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=150, penalty=none, solver=saga;, score=0.794 total time=  14.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=150, penalty=none, solver=saga;, score=0.846 total time=  14.4s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l1, solver=liblinear;, score=0.794 total time=   9.2s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l1, solver=liblinear;, score=0.846 total time=  11.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l1, solver=saga;, score=0.794 total time=  10.5s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l1, solver=saga;, score=0.846 total time=   6.8s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l2, solver=newton-cg;, score=0.794 total time=   4.2s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l2, solver=newton-cg;, score=0.846 total time=   4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l2, solver=lbfgs;, score=0.794 total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l2, solver=lbfgs;, score=0.846 total time=   3.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l2, solver=liblinear;, score=0.794 total time=   1.3s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l2, solver=liblinear;, score=0.846 total time=   1.6s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l2, solver=sag;, score=0.794 total time=   2.6s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l2, solver=sag;, score=0.846 total time=   2.9s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=l2, solver=saga;, score=0.794 total time=   2.5s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=l2, solver=saga;, score=0.846 total time=   3.6s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.1s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=saga;, score=nan total time=   0.1s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=elasticnet, solver=saga;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=180, penalty=none, solver=newton-cg;, score=0.794 total time=   9.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=180, penalty=none, solver=newton-cg;, score=0.846 total time=  11.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=180, penalty=none, solver=lbfgs;, score=0.794 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=180, penalty=none, solver=lbfgs;, score=0.846 total time=   4.2s\n",
            "[CV 1/2] END C=1.5, max_iter=180, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=1.5, max_iter=180, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=180, penalty=none, solver=sag;, score=0.794 total time=  16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=180, penalty=none, solver=sag;, score=0.846 total time=  16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=1.5, max_iter=180, penalty=none, solver=saga;, score=0.794 total time=  17.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=1.5, max_iter=180, penalty=none, solver=saga;, score=0.846 total time=  16.9s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.794 total time=   8.7s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l1, solver=liblinear;, score=0.846 total time=  15.2s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.794 total time=   3.6s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l1, solver=saga;, score=0.846 total time=   3.6s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l2, solver=newton-cg;, score=0.794 total time=   3.3s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l2, solver=newton-cg;, score=0.845 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.794 total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs;, score=0.845 total time=   1.7s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.794 total time=   1.5s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l2, solver=liblinear;, score=0.845 total time=   1.9s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.794 total time=   2.2s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l2, solver=sag;, score=0.845 total time=   2.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.794 total time=   2.2s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=l2, solver=saga;, score=0.845 total time=   1.8s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=100, penalty=none, solver=newton-cg;, score=0.794 total time=   9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=100, penalty=none, solver=newton-cg;, score=0.846 total time=  11.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=100, penalty=none, solver=lbfgs;, score=0.794 total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=100, penalty=none, solver=lbfgs;, score=0.845 total time=   1.7s\n",
            "[CV 1/2] END C=0.5, max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=100, penalty=none, solver=sag;, score=0.794 total time=   9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=100, penalty=none, solver=sag;, score=0.846 total time=   9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=100, penalty=none, solver=saga;, score=0.794 total time=   9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=100, penalty=none, solver=saga;, score=0.846 total time=   9.9s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l1, solver=liblinear;, score=0.794 total time=  12.5s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l1, solver=liblinear;, score=0.846 total time=  19.7s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l1, solver=saga;, score=0.794 total time=   3.8s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l1, solver=saga;, score=0.846 total time=   3.1s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l2, solver=newton-cg;, score=0.794 total time=   3.1s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l2, solver=newton-cg;, score=0.845 total time=   4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l2, solver=lbfgs;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l2, solver=lbfgs;, score=0.845 total time=   2.4s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l2, solver=liblinear;, score=0.794 total time=   1.1s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l2, solver=liblinear;, score=0.845 total time=   1.3s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l2, solver=sag;, score=0.794 total time=   3.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l2, solver=sag;, score=0.845 total time=   2.1s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=l2, solver=saga;, score=0.794 total time=   2.2s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=l2, solver=saga;, score=0.845 total time=   1.9s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=150, penalty=none, solver=newton-cg;, score=0.794 total time=  10.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=150, penalty=none, solver=newton-cg;, score=0.846 total time=  11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=150, penalty=none, solver=lbfgs;, score=0.794 total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=150, penalty=none, solver=lbfgs;, score=0.846 total time=   2.5s\n",
            "[CV 1/2] END C=0.5, max_iter=150, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=150, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=150, penalty=none, solver=sag;, score=0.794 total time=  14.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=150, penalty=none, solver=sag;, score=0.846 total time=  14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=150, penalty=none, solver=saga;, score=0.794 total time=  14.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=150, penalty=none, solver=saga;, score=0.846 total time=  14.5s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l1, solver=liblinear;, score=0.794 total time=   6.5s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l1, solver=liblinear;, score=0.846 total time=  11.3s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l1, solver=saga;, score=0.794 total time=   5.7s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l1, solver=saga;, score=0.846 total time=   4.4s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l2, solver=newton-cg;, score=0.794 total time=   2.8s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l2, solver=newton-cg;, score=0.845 total time=   3.5s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l2, solver=lbfgs;, score=0.794 total time=   4.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l2, solver=lbfgs;, score=0.845 total time=   2.4s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l2, solver=liblinear;, score=0.794 total time=   1.2s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l2, solver=liblinear;, score=0.845 total time=   1.3s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l2, solver=sag;, score=0.794 total time=   2.4s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l2, solver=sag;, score=0.845 total time=   2.5s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=l2, solver=saga;, score=0.794 total time=   2.9s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=l2, solver=saga;, score=0.845 total time=   2.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=180, penalty=none, solver=newton-cg;, score=0.794 total time=  10.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=180, penalty=none, solver=newton-cg;, score=0.846 total time=  11.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=180, penalty=none, solver=lbfgs;, score=0.794 total time=   3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=180, penalty=none, solver=lbfgs;, score=0.846 total time=   3.0s\n",
            "[CV 1/2] END C=0.5, max_iter=180, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/2] END C=0.5, max_iter=180, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=180, penalty=none, solver=sag;, score=0.794 total time=  16.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=180, penalty=none, solver=sag;, score=0.846 total time=  17.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/2] END C=0.5, max_iter=180, penalty=none, solver=saga;, score=0.794 total time=  18.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "162 fits failed out of a total of 360.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1863, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.82026826        nan 0.82026552 0.81982946\n",
            " 0.81981308 0.81984717 0.81983853 0.81982946        nan        nan\n",
            "        nan        nan        nan 0.82030561 0.81979171        nan\n",
            " 0.82030561 0.82030561        nan        nan 0.82026826        nan\n",
            " 0.82026552 0.81982946 0.81987182 0.81984717 0.81984307 0.81982946\n",
            "        nan        nan        nan        nan        nan 0.82030561\n",
            " 0.8200954         nan 0.82030561 0.82030561        nan        nan\n",
            " 0.82027171        nan 0.82026552 0.81982946 0.819838   0.81984717\n",
            " 0.81984555 0.81982946        nan        nan        nan        nan\n",
            "        nan 0.82030561 0.82027532        nan 0.82030561 0.82030561\n",
            "        nan        nan 0.82027858        nan 0.82023775 0.8200293\n",
            " 0.82006418 0.82003859 0.82003265 0.8200293         nan        nan\n",
            "        nan        nan        nan 0.82030561 0.81979171        nan\n",
            " 0.82030561 0.82030561        nan        nan 0.82029489        nan\n",
            " 0.82023775 0.8200293  0.82003427 0.82003859 0.82001712 0.8200293\n",
            "        nan        nan        nan        nan        nan 0.82030561\n",
            " 0.8200954         nan 0.82030561 0.82030561        nan        nan\n",
            " 0.82028885        nan 0.82023775 0.8200293  0.8200246  0.82003859\n",
            " 0.82001912 0.8200293         nan        nan        nan        nan\n",
            "        nan 0.82030561 0.82027532        nan 0.82030561 0.82030561\n",
            "        nan        nan 0.82019693        nan 0.82017537 0.81956898\n",
            " 0.81962936 0.81959117 0.81957446 0.81957306        nan        nan\n",
            "        nan        nan        nan 0.82030561 0.81979171        nan\n",
            " 0.82030561 0.82030561        nan        nan 0.82018815        nan\n",
            " 0.82017537 0.81956898 0.81954722 0.81959117 0.8195708  0.81956687\n",
            "        nan        nan        nan        nan        nan 0.82030561\n",
            " 0.8200954         nan 0.82030561 0.82030561        nan        nan\n",
            " 0.82020249        nan 0.82017537 0.81956898 0.81955341 0.81959117\n",
            " 0.81956884 0.81957306        nan        nan        nan        nan\n",
            "        nan 0.82030561 0.82027532        nan 0.82030561 0.82030561]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/2] END C=0.5, max_iter=180, penalty=none, solver=saga;, score=0.846 total time=  18.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=LogisticRegression(),\n",
              "             param_grid={'C': [1.0, 1.5, 0.5], 'max_iter': [100, 150, 180],\n",
              "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
              "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
              "                                    'saga']},\n",
              "             scoring='f1', verbose=4)"
            ],
            "text/html": [
              "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=LogisticRegression(),\n",
              "             param_grid={&#x27;C&#x27;: [1.0, 1.5, 0.5], &#x27;max_iter&#x27;: [100, 150, 180],\n",
              "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
              "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
              "                                    &#x27;saga&#x27;]},\n",
              "             scoring=&#x27;f1&#x27;, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=LogisticRegression(),\n",
              "             param_grid={&#x27;C&#x27;: [1.0, 1.5, 0.5], &#x27;max_iter&#x27;: [100, 150, 180],\n",
              "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
              "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
              "                                    &#x27;saga&#x27;]},\n",
              "             scoring=&#x27;f1&#x27;, verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "hzmQFYqpxVw_",
        "outputId": "5743e948-d06b-4b6d-bdd2-02a973e74257"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(penalty='none', solver='newton-cg')"
            ],
            "text/html": [
              "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;none&#x27;, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" checked><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;none&#x27;, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t35jNt0cluJW"
      },
      "outputs": [],
      "source": [
        "model1_be = LogisticRegression(C=1.5)\n",
        "model1_be.fit(X_train_resampled,y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_be = LogisticRegression(max_iter=180, penalty='none')\n",
        "model2_be.fit(X_train_resampled,y_train_resampled)"
      ],
      "metadata": {
        "id": "mO7rvbu4Ifvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3_be = LogisticRegression(penalty='none', solver='newton-cg')\n",
        "model3_be.fit(X_train_resampled,y_train_resampled)"
      ],
      "metadata": {
        "id": "lc3tqEWuLncA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig00azmlluJW",
        "outputId": "afc8ee2c-3e53-4f34-cc88-4d972d173998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Results of M1 model ----------\n",
            "Accuracy Score of Model1_train :  0.8365681492751029\n",
            "Accuracy Score of Model1_test :  0.5601353990365838\n",
            "---------- Training Data ----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.56      0.72     38259\n",
            "           1       0.01      0.61      0.01       146\n",
            "\n",
            "    accuracy                           0.56     38405\n",
            "   macro avg       0.50      0.58      0.36     38405\n",
            "weighted avg       0.99      0.56      0.71     38405\n",
            "\n",
            "[[21423 16836]\n",
            " [   57    89]]\n",
            "---------- Test Data ----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83     89392\n",
            "           1       0.82      0.86      0.84     89392\n",
            "\n",
            "    accuracy                           0.84    178784\n",
            "   macro avg       0.84      0.84      0.84    178784\n",
            "weighted avg       0.84      0.84      0.84    178784\n",
            "\n",
            "[[72756 16636]\n",
            " [12583 76809]]\n"
          ]
        }
      ],
      "source": [
        "### Results of M1 model\n",
        "\n",
        "y_pred_m1 = model1_be.predict(X_test)\n",
        "y_train_predict_m1 = model1_be.predict(X_train_resampled)\n",
        "print(\"--\"*5,\"Results of M1 model\",\"--\"*5)\n",
        "print(\"Accuracy Score of Model1_train : \", accuracy_score(y_train_resampled,y_train_predict_m1))\n",
        "print(\"Accuracy Score of Model1_test : \", accuracy_score(y_test,y_pred_m1))\n",
        "print('--'*5,\"Training Data\",'--'*5)\n",
        "print(classification_report(y_test, y_pred_m1))\n",
        "print(confusion_matrix(y_test, y_pred_m1))\n",
        "print('--'*5,\"Test Data\",'--'*5)\n",
        "print(classification_report(y_train_resampled, y_train_predict_m1))\n",
        "print(confusion_matrix(y_train_resampled, y_train_predict_m1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uos63UCKluJW",
        "outputId": "2152699e-1636-4e0e-9526-c9944fa06f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Results of M2 model ----------\n",
            "Accuracy Score of Model2_train :  0.8368534097010918\n",
            "Accuracy Score of Model2_test :  0.5601093607603177\n",
            "---------- Training Data ----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.56      0.72     38259\n",
            "           1       0.01      0.62      0.01       146\n",
            "\n",
            "    accuracy                           0.56     38405\n",
            "   macro avg       0.50      0.59      0.36     38405\n",
            "weighted avg       0.99      0.56      0.71     38405\n",
            "\n",
            "[[21421 16838]\n",
            " [   56    90]]\n",
            "---------- Test Data ----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83     89392\n",
            "           1       0.82      0.86      0.84     89392\n",
            "\n",
            "    accuracy                           0.84    178784\n",
            "   macro avg       0.84      0.84      0.84    178784\n",
            "weighted avg       0.84      0.84      0.84    178784\n",
            "\n",
            "[[72783 16609]\n",
            " [12559 76833]]\n"
          ]
        }
      ],
      "source": [
        "### Results of M2 model\n",
        "\n",
        "y_pred_m2 = model2_be.predict(X_test)\n",
        "y_train_predict_m2 = model2_be.predict(X_train_resampled)\n",
        "print(\"--\"*5,\"Results of M2 model\",\"--\"*5)\n",
        "print(\"Accuracy Score of Model2_train : \", accuracy_score(y_train_resampled,y_train_predict_m2))\n",
        "print(\"Accuracy Score of Model2_test : \", accuracy_score(y_test,y_pred_m2))\n",
        "print('--'*5,\"Training Data\",'--'*5)\n",
        "print(classification_report(y_test, y_pred_m2))\n",
        "print(confusion_matrix(y_test, y_pred_m2))\n",
        "print('--'*5,\"Test Data\",'--'*5)\n",
        "print(classification_report(y_train_resampled, y_train_predict_m2))\n",
        "print(confusion_matrix(y_train_resampled, y_train_predict_m2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Results of M3 model\n",
        "\n",
        "y_pred_m3 = model3_be.predict(X_test)\n",
        "y_train_predict_m3 = model3_be.predict(X_train_resampled)\n",
        "print(\"--\"*5,\"Results of M3 model\",\"--\"*5)\n",
        "print(\"Accuracy Score of Model3_train : \", accuracy_score(y_train_resampled,y_train_predict_m3))\n",
        "print(\"Accuracy Score of Model3_test : \", accuracy_score(y_test,y_pred_m3))\n",
        "print('--'*5,\"Training Data\",'--'*5)\n",
        "print(classification_report(y_test, y_pred_m3))\n",
        "print(confusion_matrix(y_test, y_pred_m3))\n",
        "print('--'*5,\"Test Data\",'--'*5)\n",
        "print(classification_report(y_train_resampled, y_train_predict_m3))\n",
        "print(confusion_matrix(y_train_resampled, y_train_predict_m3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoxs1fbpLST8",
        "outputId": "18e59907-f265-4fc1-cfac-5dc421314d77"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Results of M3 model ----------\n",
            "Accuracy Score of Model3_train :  0.836875783067836\n",
            "Accuracy Score of Model3_test :  0.559953131102721\n",
            "---------- Training Data ----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.56      0.72     38259\n",
            "           1       0.01      0.62      0.01       146\n",
            "\n",
            "    accuracy                           0.56     38405\n",
            "   macro avg       0.50      0.59      0.36     38405\n",
            "weighted avg       0.99      0.56      0.71     38405\n",
            "\n",
            "[[21415 16844]\n",
            " [   56    90]]\n",
            "---------- Test Data ----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83     89392\n",
            "           1       0.82      0.86      0.84     89392\n",
            "\n",
            "    accuracy                           0.84    178784\n",
            "   macro avg       0.84      0.84      0.84    178784\n",
            "weighted avg       0.84      0.84      0.84    178784\n",
            "\n",
            "[[72784 16608]\n",
            " [12556 76836]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wQrA_JIluJX"
      },
      "outputs": [],
      "source": [
        "#### Applying SVM\n",
        "from  sklearn import svm\n",
        "model4 = svm.SVC(kernel=\"poly\", degree =1, decision_function_shape='ovo',gamma = 'auto')\n",
        "model4.fit(X_train_resampled,y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dpm2aCwluJX"
      },
      "outputs": [],
      "source": [
        "### Results of M4 model\n",
        "\n",
        "y_pred_m4 = model4.predict(X_test)\n",
        "y_train_predict_m4 = model4.predict(X_train_resampled)\n",
        "print(\"--\"*5,\"Results of M4 model\",\"--\"*5)\n",
        "print(\"Accuracy Score of Model4_train : \", accuracy_score(y_train_resampled,y_train_predict_m4))\n",
        "print(\"Accuracy Score of Model4_test : \", accuracy_score(y_test,y_pred_m4))\n",
        "print('--'*5,\"Training Data\",'--'*5)\n",
        "print(classification_report(y_test, y_pred_m4))\n",
        "print(confusion_matrix(y_test, y_pred_m4))\n",
        "print('--'*5,\"Test Data\",'--'*5)\n",
        "print(classification_report(y_train_resampled, y_train_predict_m4))\n",
        "print(confusion_matrix(y_train_resampled, y_train_predict_m4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQPD7Mc2luJX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "score = cross_val_score(model1,X_test,y_test,cv=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcrpRWd2luJY"
      },
      "outputs": [],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgsZsVD_luJY"
      },
      "outputs": [],
      "source": [
        "## Apply RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model5 = RandomForestClassifier()\n",
        "model5.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4waKG6gCluJY"
      },
      "outputs": [],
      "source": [
        "### Results of M5 model\n",
        "\n",
        "y_pred_m5 = model5.predict(X_test)\n",
        "y_train_predict_m5 = model5.predict(X_train_resampled)\n",
        "print(\"--\"*5,\"Results of M5 model\",\"--\"*5)\n",
        "print(\"Accuracy Score of Model5_train : \", accuracy_score(y_train_resampled,y_train_predict_m5))\n",
        "print(\"Accuracy Score of Model5_test : \", accuracy_score(y_test,y_pred_m5))\n",
        "print('--'*5,\"Training Data\",'--'*5)\n",
        "print(classification_report(y_test, y_pred_m5))\n",
        "print(confusion_matrix(y_test, y_pred_m5))\n",
        "print('--'*5,\"Test Data\",'--'*5)\n",
        "print(classification_report(y_train_resampled, y_train_predict_m5))\n",
        "print(confusion_matrix(y_train_resampled, y_train_predict_m5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8RYFW2YluJZ"
      },
      "outputs": [],
      "source": [
        "## Apply LGBM Classifier\n",
        "lgb_model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, n_jobs=1)\n",
        "lgb_model.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlo0ZQBzluJa"
      },
      "outputs": [],
      "source": [
        "y_pred = lgb_model.predict(X_test)\n",
        "y_train_predict = lgb_model.predict(X_train_resampled)\n",
        "\n",
        "print(\"Accuracy Score of Model1_train : \", accuracy_score(y_train_resampled,y_train_predict))\n",
        "print(\"Accuracy Score of Model1_test : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grQ-CQDaluJa"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('--'*50)\n",
        "print(classification_report(y_train_resampled, y_train_predict))\n",
        "print(confusion_matrix(y_train_resampled, y_train_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jR6j9-hluJa"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada_classifier=AdaBoostClassifier()\n",
        "ada_classifier.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fn9LxgZluJa"
      },
      "outputs": [],
      "source": [
        "y_pred = ada_classifier.predict(X_test)\n",
        "y_train_predict = ada_classifier.predict(X_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fStAj7fTluJb"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Score of Model1_train : \", accuracy_score(y_train_resampled,y_train_predict))\n",
        "print(\"Accuracy Score of Model1_test : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KduZh2BeluJb"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_classifier=KNeighborsClassifier()\n",
        "knn_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qCoPAHaluJb"
      },
      "outputs": [],
      "source": [
        "y_pred = knn_classifier.predict(X_test)\n",
        "y_train_predict = knn_classifier.predict(X_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dICwmf3luJb"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Score of Model1_train : \", accuracy_score(y_train_resampled,y_train_predict))\n",
        "print(\"Accuracy Score of Model1_test : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djR11dv2luJb"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "xgb_m=xgboost.XGBClassifier()\n",
        "xgb_m.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIDNch1cluJc"
      },
      "outputs": [],
      "source": [
        "y_pred = xgb_m.predict(X_test)\n",
        "y_train_predict = xgb_m.predict(X_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCc_r0pWluJc"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Score of Model1_train : \", accuracy_score(y_train_resampled,y_train_predict))\n",
        "print(\"Accuracy Score of Model1_test : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VBGdokZluJc"
      },
      "outputs": [],
      "source": [
        "params={\n",
        " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
        " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
        " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUuMjJKVluJc"
      },
      "outputs": [],
      "source": [
        "## Hyperparameter optimization using RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "random_search=RandomizedSearchCV(xgb_m,param_distributions=params,n_iter=5,scoring='accuracy',n_jobs=-1,cv=5,verbose=3)\n",
        "random_search.fit(X_train_resampled,y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vkTrmCwluJc"
      },
      "outputs": [],
      "source": [
        "y_pred = random_search.predict(X_test)\n",
        "y_train_predict = random_search.predict(X_train_resampled)\n",
        "\n",
        "print(\"Accuracy Score of Model1_train : \", accuracy_score(y_train_resampled,y_train_predict))\n",
        "print(\"Accuracy Score of Model1_test : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE_3lJcvluJd"
      },
      "outputs": [],
      "source": [
        "base_models = [\n",
        "    ('catboost', CatBoostClassifier(\n",
        "        iterations=100,\n",
        "        learning_rate=0.1,\n",
        "        depth=6,\n",
        "        random_state=42\n",
        "    )),\n",
        "    ('xgboost', xgboost.XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        random_state=42\n",
        "    )),\n",
        "    ('lightgbm', LGBMClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42,\n",
        "        n_jobs =1\n",
        "    )),\n",
        "    ('Logistic',LogisticRegression(\n",
        "        penalty='none', solver='newton-cg'\n",
        "    ))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCTG2E5HluJd"
      },
      "outputs": [],
      "source": [
        "meta_model = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtBHHW8jluJd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vw6OyHUkluJd",
        "outputId": "5c0b033f-b578-46d7-e432-443d906f854e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.5617382\ttotal: 51ms\tremaining: 5.05s\n",
            "1:\tlearn: 0.4666516\ttotal: 99.4ms\tremaining: 4.87s\n",
            "2:\tlearn: 0.4019319\ttotal: 143ms\tremaining: 4.63s\n",
            "3:\tlearn: 0.3571307\ttotal: 185ms\tremaining: 4.44s\n",
            "4:\tlearn: 0.3224676\ttotal: 229ms\tremaining: 4.34s\n",
            "5:\tlearn: 0.2969781\ttotal: 279ms\tremaining: 4.38s\n",
            "6:\tlearn: 0.2755221\ttotal: 355ms\tremaining: 4.72s\n",
            "7:\tlearn: 0.2479807\ttotal: 403ms\tremaining: 4.63s\n",
            "8:\tlearn: 0.2309756\ttotal: 444ms\tremaining: 4.49s\n",
            "9:\tlearn: 0.2187999\ttotal: 488ms\tremaining: 4.4s\n",
            "10:\tlearn: 0.2032517\ttotal: 529ms\tremaining: 4.28s\n",
            "11:\tlearn: 0.1930926\ttotal: 568ms\tremaining: 4.17s\n",
            "12:\tlearn: 0.1834596\ttotal: 606ms\tremaining: 4.05s\n",
            "13:\tlearn: 0.1745252\ttotal: 638ms\tremaining: 3.92s\n",
            "14:\tlearn: 0.1677816\ttotal: 695ms\tremaining: 3.94s\n",
            "15:\tlearn: 0.1609010\ttotal: 754ms\tremaining: 3.96s\n",
            "16:\tlearn: 0.1547764\ttotal: 800ms\tremaining: 3.9s\n",
            "17:\tlearn: 0.1503973\ttotal: 838ms\tremaining: 3.82s\n",
            "18:\tlearn: 0.1456393\ttotal: 878ms\tremaining: 3.74s\n",
            "19:\tlearn: 0.1419347\ttotal: 927ms\tremaining: 3.71s\n",
            "20:\tlearn: 0.1369302\ttotal: 969ms\tremaining: 3.65s\n",
            "21:\tlearn: 0.1330102\ttotal: 1.02s\tremaining: 3.62s\n",
            "22:\tlearn: 0.1297547\ttotal: 1.06s\tremaining: 3.57s\n",
            "23:\tlearn: 0.1263863\ttotal: 1.11s\tremaining: 3.51s\n",
            "24:\tlearn: 0.1220232\ttotal: 1.15s\tremaining: 3.45s\n",
            "25:\tlearn: 0.1193595\ttotal: 1.19s\tremaining: 3.4s\n",
            "26:\tlearn: 0.1158018\ttotal: 1.24s\tremaining: 3.36s\n",
            "27:\tlearn: 0.1124750\ttotal: 1.29s\tremaining: 3.32s\n",
            "28:\tlearn: 0.1095435\ttotal: 1.34s\tremaining: 3.29s\n",
            "29:\tlearn: 0.1065872\ttotal: 1.43s\tremaining: 3.33s\n",
            "30:\tlearn: 0.1042716\ttotal: 1.48s\tremaining: 3.3s\n",
            "31:\tlearn: 0.1013866\ttotal: 1.53s\tremaining: 3.25s\n",
            "32:\tlearn: 0.0994445\ttotal: 1.58s\tremaining: 3.21s\n",
            "33:\tlearn: 0.0971726\ttotal: 1.63s\tremaining: 3.16s\n",
            "34:\tlearn: 0.0956182\ttotal: 1.68s\tremaining: 3.11s\n",
            "35:\tlearn: 0.0919240\ttotal: 1.72s\tremaining: 3.06s\n",
            "36:\tlearn: 0.0903159\ttotal: 1.77s\tremaining: 3.01s\n",
            "37:\tlearn: 0.0882226\ttotal: 1.81s\tremaining: 2.96s\n",
            "38:\tlearn: 0.0866736\ttotal: 1.85s\tremaining: 2.89s\n",
            "39:\tlearn: 0.0851157\ttotal: 1.89s\tremaining: 2.83s\n",
            "40:\tlearn: 0.0837620\ttotal: 1.93s\tremaining: 2.78s\n",
            "41:\tlearn: 0.0821374\ttotal: 1.97s\tremaining: 2.72s\n",
            "42:\tlearn: 0.0810999\ttotal: 2.01s\tremaining: 2.67s\n",
            "43:\tlearn: 0.0792493\ttotal: 2.05s\tremaining: 2.61s\n",
            "44:\tlearn: 0.0775710\ttotal: 2.11s\tremaining: 2.58s\n",
            "45:\tlearn: 0.0764238\ttotal: 2.16s\tremaining: 2.54s\n",
            "46:\tlearn: 0.0751432\ttotal: 2.21s\tremaining: 2.49s\n",
            "47:\tlearn: 0.0740219\ttotal: 2.26s\tremaining: 2.45s\n",
            "48:\tlearn: 0.0727675\ttotal: 2.31s\tremaining: 2.4s\n",
            "49:\tlearn: 0.0719090\ttotal: 2.36s\tremaining: 2.36s\n",
            "50:\tlearn: 0.0709314\ttotal: 2.4s\tremaining: 2.31s\n",
            "51:\tlearn: 0.0700726\ttotal: 2.46s\tremaining: 2.27s\n",
            "52:\tlearn: 0.0689839\ttotal: 2.53s\tremaining: 2.25s\n",
            "53:\tlearn: 0.0681930\ttotal: 2.58s\tremaining: 2.2s\n",
            "54:\tlearn: 0.0672599\ttotal: 2.63s\tremaining: 2.15s\n",
            "55:\tlearn: 0.0657714\ttotal: 2.67s\tremaining: 2.1s\n",
            "56:\tlearn: 0.0648166\ttotal: 2.72s\tremaining: 2.05s\n",
            "57:\tlearn: 0.0640094\ttotal: 2.76s\tremaining: 2s\n",
            "58:\tlearn: 0.0631943\ttotal: 2.8s\tremaining: 1.95s\n",
            "59:\tlearn: 0.0624071\ttotal: 2.84s\tremaining: 1.9s\n",
            "60:\tlearn: 0.0616259\ttotal: 2.89s\tremaining: 1.84s\n",
            "61:\tlearn: 0.0608797\ttotal: 2.93s\tremaining: 1.79s\n",
            "62:\tlearn: 0.0602670\ttotal: 2.97s\tremaining: 1.75s\n",
            "63:\tlearn: 0.0595194\ttotal: 3.01s\tremaining: 1.7s\n",
            "64:\tlearn: 0.0588250\ttotal: 3.06s\tremaining: 1.65s\n",
            "65:\tlearn: 0.0582452\ttotal: 3.1s\tremaining: 1.6s\n",
            "66:\tlearn: 0.0574763\ttotal: 3.14s\tremaining: 1.55s\n",
            "67:\tlearn: 0.0569497\ttotal: 3.18s\tremaining: 1.49s\n",
            "68:\tlearn: 0.0563986\ttotal: 3.22s\tremaining: 1.45s\n",
            "69:\tlearn: 0.0558273\ttotal: 3.26s\tremaining: 1.4s\n",
            "70:\tlearn: 0.0551629\ttotal: 3.3s\tremaining: 1.35s\n",
            "71:\tlearn: 0.0544255\ttotal: 3.35s\tremaining: 1.3s\n",
            "72:\tlearn: 0.0535833\ttotal: 3.39s\tremaining: 1.25s\n",
            "73:\tlearn: 0.0528964\ttotal: 3.43s\tremaining: 1.21s\n",
            "74:\tlearn: 0.0523828\ttotal: 3.47s\tremaining: 1.16s\n",
            "75:\tlearn: 0.0518810\ttotal: 3.52s\tremaining: 1.11s\n",
            "76:\tlearn: 0.0513636\ttotal: 3.59s\tremaining: 1.07s\n",
            "77:\tlearn: 0.0510264\ttotal: 3.63s\tremaining: 1.02s\n",
            "78:\tlearn: 0.0503166\ttotal: 3.67s\tremaining: 976ms\n",
            "79:\tlearn: 0.0499027\ttotal: 3.71s\tremaining: 928ms\n",
            "80:\tlearn: 0.0493646\ttotal: 3.75s\tremaining: 881ms\n",
            "81:\tlearn: 0.0489362\ttotal: 3.8s\tremaining: 834ms\n",
            "82:\tlearn: 0.0483636\ttotal: 3.84s\tremaining: 787ms\n",
            "83:\tlearn: 0.0476999\ttotal: 3.88s\tremaining: 740ms\n",
            "84:\tlearn: 0.0473447\ttotal: 3.92s\tremaining: 693ms\n",
            "85:\tlearn: 0.0461796\ttotal: 3.98s\tremaining: 647ms\n",
            "86:\tlearn: 0.0455790\ttotal: 4.02s\tremaining: 600ms\n",
            "87:\tlearn: 0.0452628\ttotal: 4.06s\tremaining: 554ms\n",
            "88:\tlearn: 0.0449464\ttotal: 4.1s\tremaining: 507ms\n",
            "89:\tlearn: 0.0445110\ttotal: 4.14s\tremaining: 460ms\n",
            "90:\tlearn: 0.0439273\ttotal: 4.18s\tremaining: 414ms\n",
            "91:\tlearn: 0.0435820\ttotal: 4.22s\tremaining: 367ms\n",
            "92:\tlearn: 0.0431765\ttotal: 4.27s\tremaining: 321ms\n",
            "93:\tlearn: 0.0429232\ttotal: 4.3s\tremaining: 275ms\n",
            "94:\tlearn: 0.0424718\ttotal: 4.35s\tremaining: 229ms\n",
            "95:\tlearn: 0.0421985\ttotal: 4.39s\tremaining: 183ms\n",
            "96:\tlearn: 0.0418822\ttotal: 4.43s\tremaining: 137ms\n",
            "97:\tlearn: 0.0415928\ttotal: 4.47s\tremaining: 91.2ms\n",
            "98:\tlearn: 0.0412282\ttotal: 4.51s\tremaining: 45.6ms\n",
            "99:\tlearn: 0.0409301\ttotal: 4.55s\tremaining: 0us\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:45:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 89392, number of negative: 89392\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073763 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1851\n",
            "[LightGBM] [Info] Number of data points in the train set: 178784, number of used features: 41\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:477: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:477: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:477: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.5263964\ttotal: 52.4ms\tremaining: 5.19s\n",
            "1:\tlearn: 0.4169071\ttotal: 89.5ms\tremaining: 4.39s\n",
            "2:\tlearn: 0.3465447\ttotal: 124ms\tremaining: 4.02s\n",
            "3:\tlearn: 0.2894939\ttotal: 161ms\tremaining: 3.87s\n",
            "4:\tlearn: 0.2549382\ttotal: 197ms\tremaining: 3.75s\n",
            "5:\tlearn: 0.2257771\ttotal: 234ms\tremaining: 3.66s\n",
            "6:\tlearn: 0.2059680\ttotal: 271ms\tremaining: 3.6s\n",
            "7:\tlearn: 0.1881374\ttotal: 306ms\tremaining: 3.52s\n",
            "8:\tlearn: 0.1779084\ttotal: 344ms\tremaining: 3.48s\n",
            "9:\tlearn: 0.1669918\ttotal: 407ms\tremaining: 3.67s\n",
            "10:\tlearn: 0.1532261\ttotal: 444ms\tremaining: 3.59s\n",
            "11:\tlearn: 0.1445467\ttotal: 478ms\tremaining: 3.51s\n",
            "12:\tlearn: 0.1372710\ttotal: 512ms\tremaining: 3.43s\n",
            "13:\tlearn: 0.1309692\ttotal: 548ms\tremaining: 3.37s\n",
            "14:\tlearn: 0.1235238\ttotal: 584ms\tremaining: 3.31s\n",
            "15:\tlearn: 0.1181587\ttotal: 627ms\tremaining: 3.29s\n",
            "16:\tlearn: 0.1121372\ttotal: 662ms\tremaining: 3.23s\n",
            "17:\tlearn: 0.1082778\ttotal: 697ms\tremaining: 3.17s\n",
            "18:\tlearn: 0.1038058\ttotal: 732ms\tremaining: 3.12s\n",
            "19:\tlearn: 0.0994076\ttotal: 766ms\tremaining: 3.06s\n",
            "20:\tlearn: 0.0950128\ttotal: 804ms\tremaining: 3.02s\n",
            "21:\tlearn: 0.0923913\ttotal: 838ms\tremaining: 2.97s\n",
            "22:\tlearn: 0.0897724\ttotal: 876ms\tremaining: 2.93s\n",
            "23:\tlearn: 0.0872025\ttotal: 911ms\tremaining: 2.88s\n",
            "24:\tlearn: 0.0841354\ttotal: 946ms\tremaining: 2.84s\n",
            "25:\tlearn: 0.0807074\ttotal: 982ms\tremaining: 2.79s\n",
            "26:\tlearn: 0.0784065\ttotal: 1.02s\tremaining: 2.75s\n",
            "27:\tlearn: 0.0763443\ttotal: 1.05s\tremaining: 2.71s\n",
            "28:\tlearn: 0.0745577\ttotal: 1.09s\tremaining: 2.67s\n",
            "29:\tlearn: 0.0728480\ttotal: 1.13s\tremaining: 2.64s\n",
            "30:\tlearn: 0.0712247\ttotal: 1.17s\tremaining: 2.61s\n",
            "31:\tlearn: 0.0693329\ttotal: 1.21s\tremaining: 2.57s\n",
            "32:\tlearn: 0.0673851\ttotal: 1.24s\tremaining: 2.52s\n",
            "33:\tlearn: 0.0660139\ttotal: 1.28s\tremaining: 2.48s\n",
            "34:\tlearn: 0.0646259\ttotal: 1.31s\tremaining: 2.44s\n",
            "35:\tlearn: 0.0632820\ttotal: 1.35s\tremaining: 2.4s\n",
            "36:\tlearn: 0.0618202\ttotal: 1.39s\tremaining: 2.36s\n",
            "37:\tlearn: 0.0606542\ttotal: 1.44s\tremaining: 2.35s\n",
            "38:\tlearn: 0.0595419\ttotal: 1.5s\tremaining: 2.35s\n",
            "39:\tlearn: 0.0576966\ttotal: 1.54s\tremaining: 2.31s\n",
            "40:\tlearn: 0.0559002\ttotal: 1.59s\tremaining: 2.28s\n",
            "41:\tlearn: 0.0548384\ttotal: 1.63s\tremaining: 2.25s\n",
            "42:\tlearn: 0.0536608\ttotal: 1.67s\tremaining: 2.21s\n",
            "43:\tlearn: 0.0526572\ttotal: 1.73s\tremaining: 2.2s\n",
            "44:\tlearn: 0.0515519\ttotal: 1.77s\tremaining: 2.16s\n",
            "45:\tlearn: 0.0503191\ttotal: 1.83s\tremaining: 2.15s\n",
            "46:\tlearn: 0.0493447\ttotal: 1.86s\tremaining: 2.1s\n",
            "47:\tlearn: 0.0484015\ttotal: 1.9s\tremaining: 2.06s\n",
            "48:\tlearn: 0.0472054\ttotal: 1.93s\tremaining: 2.01s\n",
            "49:\tlearn: 0.0462783\ttotal: 1.97s\tremaining: 1.97s\n",
            "50:\tlearn: 0.0451209\ttotal: 2.01s\tremaining: 1.93s\n",
            "51:\tlearn: 0.0443657\ttotal: 2.04s\tremaining: 1.89s\n",
            "52:\tlearn: 0.0438175\ttotal: 2.08s\tremaining: 1.84s\n",
            "53:\tlearn: 0.0431768\ttotal: 2.11s\tremaining: 1.8s\n",
            "54:\tlearn: 0.0424572\ttotal: 2.15s\tremaining: 1.76s\n",
            "55:\tlearn: 0.0418509\ttotal: 2.18s\tremaining: 1.71s\n",
            "56:\tlearn: 0.0410615\ttotal: 2.22s\tremaining: 1.67s\n",
            "57:\tlearn: 0.0404716\ttotal: 2.25s\tremaining: 1.63s\n",
            "58:\tlearn: 0.0399249\ttotal: 2.29s\tremaining: 1.59s\n",
            "59:\tlearn: 0.0395212\ttotal: 2.32s\tremaining: 1.54s\n",
            "60:\tlearn: 0.0387941\ttotal: 2.35s\tremaining: 1.5s\n",
            "61:\tlearn: 0.0381444\ttotal: 2.38s\tremaining: 1.46s\n",
            "62:\tlearn: 0.0373701\ttotal: 2.42s\tremaining: 1.42s\n",
            "63:\tlearn: 0.0366458\ttotal: 2.45s\tremaining: 1.38s\n",
            "64:\tlearn: 0.0360473\ttotal: 2.51s\tremaining: 1.35s\n",
            "65:\tlearn: 0.0355655\ttotal: 2.56s\tremaining: 1.32s\n",
            "66:\tlearn: 0.0351006\ttotal: 2.6s\tremaining: 1.28s\n",
            "67:\tlearn: 0.0345137\ttotal: 2.64s\tremaining: 1.24s\n",
            "68:\tlearn: 0.0341257\ttotal: 2.67s\tremaining: 1.2s\n",
            "69:\tlearn: 0.0337911\ttotal: 2.71s\tremaining: 1.16s\n",
            "70:\tlearn: 0.0333316\ttotal: 2.74s\tremaining: 1.12s\n",
            "71:\tlearn: 0.0329769\ttotal: 2.78s\tremaining: 1.08s\n",
            "72:\tlearn: 0.0325853\ttotal: 2.82s\tremaining: 1.04s\n",
            "73:\tlearn: 0.0309690\ttotal: 2.85s\tremaining: 1s\n",
            "74:\tlearn: 0.0306003\ttotal: 2.89s\tremaining: 963ms\n",
            "75:\tlearn: 0.0303441\ttotal: 2.92s\tremaining: 924ms\n",
            "76:\tlearn: 0.0298981\ttotal: 2.96s\tremaining: 884ms\n",
            "77:\tlearn: 0.0293088\ttotal: 2.99s\tremaining: 845ms\n",
            "78:\tlearn: 0.0291134\ttotal: 3.03s\tremaining: 805ms\n",
            "79:\tlearn: 0.0288888\ttotal: 3.06s\tremaining: 766ms\n",
            "80:\tlearn: 0.0282388\ttotal: 3.1s\tremaining: 727ms\n",
            "81:\tlearn: 0.0280201\ttotal: 3.14s\tremaining: 688ms\n",
            "82:\tlearn: 0.0276725\ttotal: 3.17s\tremaining: 649ms\n",
            "83:\tlearn: 0.0274499\ttotal: 3.2s\tremaining: 610ms\n",
            "84:\tlearn: 0.0271424\ttotal: 3.24s\tremaining: 572ms\n",
            "85:\tlearn: 0.0267954\ttotal: 3.27s\tremaining: 533ms\n",
            "86:\tlearn: 0.0265499\ttotal: 3.31s\tremaining: 495ms\n",
            "87:\tlearn: 0.0262738\ttotal: 3.34s\tremaining: 456ms\n",
            "88:\tlearn: 0.0259001\ttotal: 3.38s\tremaining: 418ms\n",
            "89:\tlearn: 0.0256576\ttotal: 3.41s\tremaining: 379ms\n",
            "90:\tlearn: 0.0254151\ttotal: 3.45s\tremaining: 341ms\n",
            "91:\tlearn: 0.0251612\ttotal: 3.48s\tremaining: 303ms\n",
            "92:\tlearn: 0.0247200\ttotal: 3.52s\tremaining: 265ms\n",
            "93:\tlearn: 0.0241874\ttotal: 3.56s\tremaining: 227ms\n",
            "94:\tlearn: 0.0238510\ttotal: 3.62s\tremaining: 190ms\n",
            "95:\tlearn: 0.0236137\ttotal: 3.67s\tremaining: 153ms\n",
            "96:\tlearn: 0.0232216\ttotal: 3.7s\tremaining: 115ms\n",
            "97:\tlearn: 0.0229352\ttotal: 3.74s\tremaining: 76.3ms\n",
            "98:\tlearn: 0.0225334\ttotal: 3.78s\tremaining: 38.1ms\n",
            "99:\tlearn: 0.0221485\ttotal: 3.81s\tremaining: 0us\n",
            "0:\tlearn: 0.5648823\ttotal: 40.2ms\tremaining: 3.98s\n",
            "1:\tlearn: 0.4743659\ttotal: 76.7ms\tremaining: 3.76s\n",
            "2:\tlearn: 0.4063341\ttotal: 113ms\tremaining: 3.64s\n",
            "3:\tlearn: 0.3619762\ttotal: 148ms\tremaining: 3.56s\n",
            "4:\tlearn: 0.3255473\ttotal: 185ms\tremaining: 3.52s\n",
            "5:\tlearn: 0.3005159\ttotal: 222ms\tremaining: 3.48s\n",
            "6:\tlearn: 0.2667446\ttotal: 260ms\tremaining: 3.46s\n",
            "7:\tlearn: 0.2502221\ttotal: 297ms\tremaining: 3.41s\n",
            "8:\tlearn: 0.2329611\ttotal: 329ms\tremaining: 3.33s\n",
            "9:\tlearn: 0.2206413\ttotal: 366ms\tremaining: 3.29s\n",
            "10:\tlearn: 0.2052055\ttotal: 402ms\tremaining: 3.25s\n",
            "11:\tlearn: 0.1962466\ttotal: 448ms\tremaining: 3.29s\n",
            "12:\tlearn: 0.1851289\ttotal: 506ms\tremaining: 3.39s\n",
            "13:\tlearn: 0.1791345\ttotal: 541ms\tremaining: 3.32s\n",
            "14:\tlearn: 0.1712273\ttotal: 577ms\tremaining: 3.27s\n",
            "15:\tlearn: 0.1639334\ttotal: 613ms\tremaining: 3.22s\n",
            "16:\tlearn: 0.1569014\ttotal: 652ms\tremaining: 3.18s\n",
            "17:\tlearn: 0.1517139\ttotal: 688ms\tremaining: 3.13s\n",
            "18:\tlearn: 0.1474690\ttotal: 724ms\tremaining: 3.09s\n",
            "19:\tlearn: 0.1416074\ttotal: 760ms\tremaining: 3.04s\n",
            "20:\tlearn: 0.1380140\ttotal: 796ms\tremaining: 2.99s\n",
            "21:\tlearn: 0.1348959\ttotal: 834ms\tremaining: 2.96s\n",
            "22:\tlearn: 0.1304761\ttotal: 870ms\tremaining: 2.91s\n",
            "23:\tlearn: 0.1269584\ttotal: 905ms\tremaining: 2.87s\n",
            "24:\tlearn: 0.1226589\ttotal: 942ms\tremaining: 2.83s\n",
            "25:\tlearn: 0.1191990\ttotal: 978ms\tremaining: 2.78s\n",
            "26:\tlearn: 0.1159654\ttotal: 1.01s\tremaining: 2.74s\n",
            "27:\tlearn: 0.1124858\ttotal: 1.05s\tremaining: 2.7s\n",
            "28:\tlearn: 0.1070360\ttotal: 1.08s\tremaining: 2.65s\n",
            "29:\tlearn: 0.1047019\ttotal: 1.12s\tremaining: 2.61s\n",
            "30:\tlearn: 0.1015160\ttotal: 1.16s\tremaining: 2.57s\n",
            "31:\tlearn: 0.0988978\ttotal: 1.19s\tremaining: 2.53s\n",
            "32:\tlearn: 0.0971679\ttotal: 1.23s\tremaining: 2.49s\n",
            "33:\tlearn: 0.0952911\ttotal: 1.26s\tremaining: 2.45s\n",
            "34:\tlearn: 0.0935119\ttotal: 1.3s\tremaining: 2.41s\n",
            "35:\tlearn: 0.0916229\ttotal: 1.34s\tremaining: 2.39s\n",
            "36:\tlearn: 0.0904833\ttotal: 1.38s\tremaining: 2.35s\n",
            "37:\tlearn: 0.0889703\ttotal: 1.42s\tremaining: 2.31s\n",
            "38:\tlearn: 0.0874313\ttotal: 1.45s\tremaining: 2.27s\n",
            "39:\tlearn: 0.0858150\ttotal: 1.5s\tremaining: 2.24s\n",
            "40:\tlearn: 0.0847296\ttotal: 1.56s\tremaining: 2.24s\n",
            "41:\tlearn: 0.0833403\ttotal: 1.59s\tremaining: 2.2s\n",
            "42:\tlearn: 0.0816176\ttotal: 1.63s\tremaining: 2.16s\n",
            "43:\tlearn: 0.0800975\ttotal: 1.66s\tremaining: 2.12s\n",
            "44:\tlearn: 0.0787337\ttotal: 1.7s\tremaining: 2.08s\n",
            "45:\tlearn: 0.0775325\ttotal: 1.74s\tremaining: 2.05s\n",
            "46:\tlearn: 0.0761769\ttotal: 1.78s\tremaining: 2.01s\n",
            "47:\tlearn: 0.0749639\ttotal: 1.81s\tremaining: 1.97s\n",
            "48:\tlearn: 0.0740240\ttotal: 1.85s\tremaining: 1.93s\n",
            "49:\tlearn: 0.0727215\ttotal: 1.88s\tremaining: 1.88s\n",
            "50:\tlearn: 0.0717387\ttotal: 1.92s\tremaining: 1.85s\n",
            "51:\tlearn: 0.0708293\ttotal: 1.96s\tremaining: 1.81s\n",
            "52:\tlearn: 0.0699289\ttotal: 1.99s\tremaining: 1.77s\n",
            "53:\tlearn: 0.0691872\ttotal: 2.03s\tremaining: 1.73s\n",
            "54:\tlearn: 0.0683568\ttotal: 2.08s\tremaining: 1.7s\n",
            "55:\tlearn: 0.0672850\ttotal: 2.12s\tremaining: 1.66s\n",
            "56:\tlearn: 0.0666150\ttotal: 2.15s\tremaining: 1.63s\n",
            "57:\tlearn: 0.0656959\ttotal: 2.2s\tremaining: 1.59s\n",
            "58:\tlearn: 0.0643465\ttotal: 2.24s\tremaining: 1.55s\n",
            "59:\tlearn: 0.0620311\ttotal: 2.28s\tremaining: 1.52s\n",
            "60:\tlearn: 0.0611595\ttotal: 2.32s\tremaining: 1.49s\n",
            "61:\tlearn: 0.0605078\ttotal: 2.36s\tremaining: 1.45s\n",
            "62:\tlearn: 0.0598687\ttotal: 2.4s\tremaining: 1.41s\n",
            "63:\tlearn: 0.0592217\ttotal: 2.44s\tremaining: 1.37s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64:\tlearn: 0.0585488\ttotal: 2.48s\tremaining: 1.33s\n",
            "65:\tlearn: 0.0563922\ttotal: 2.51s\tremaining: 1.29s\n",
            "66:\tlearn: 0.0556716\ttotal: 2.55s\tremaining: 1.26s\n",
            "67:\tlearn: 0.0549495\ttotal: 2.62s\tremaining: 1.23s\n",
            "68:\tlearn: 0.0540040\ttotal: 2.66s\tremaining: 1.19s\n",
            "69:\tlearn: 0.0535683\ttotal: 2.7s\tremaining: 1.16s\n",
            "70:\tlearn: 0.0529319\ttotal: 2.73s\tremaining: 1.11s\n",
            "71:\tlearn: 0.0524170\ttotal: 2.77s\tremaining: 1.08s\n",
            "72:\tlearn: 0.0520889\ttotal: 2.8s\tremaining: 1.04s\n",
            "73:\tlearn: 0.0516722\ttotal: 2.84s\tremaining: 997ms\n",
            "74:\tlearn: 0.0513550\ttotal: 2.87s\tremaining: 957ms\n",
            "75:\tlearn: 0.0510368\ttotal: 2.92s\tremaining: 921ms\n",
            "76:\tlearn: 0.0507177\ttotal: 2.95s\tremaining: 881ms\n",
            "77:\tlearn: 0.0502513\ttotal: 2.98s\tremaining: 841ms\n",
            "78:\tlearn: 0.0497587\ttotal: 3.02s\tremaining: 802ms\n",
            "79:\tlearn: 0.0493739\ttotal: 3.05s\tremaining: 763ms\n",
            "80:\tlearn: 0.0489743\ttotal: 3.09s\tremaining: 724ms\n",
            "81:\tlearn: 0.0484752\ttotal: 3.12s\tremaining: 685ms\n",
            "82:\tlearn: 0.0476398\ttotal: 3.16s\tremaining: 646ms\n",
            "83:\tlearn: 0.0471576\ttotal: 3.21s\tremaining: 611ms\n",
            "84:\tlearn: 0.0467732\ttotal: 3.25s\tremaining: 574ms\n",
            "85:\tlearn: 0.0462531\ttotal: 3.29s\tremaining: 536ms\n",
            "86:\tlearn: 0.0458310\ttotal: 3.32s\tremaining: 497ms\n",
            "87:\tlearn: 0.0454473\ttotal: 3.36s\tremaining: 458ms\n",
            "88:\tlearn: 0.0450722\ttotal: 3.39s\tremaining: 419ms\n",
            "89:\tlearn: 0.0447033\ttotal: 3.43s\tremaining: 381ms\n",
            "90:\tlearn: 0.0443121\ttotal: 3.46s\tremaining: 343ms\n",
            "91:\tlearn: 0.0439701\ttotal: 3.5s\tremaining: 304ms\n",
            "92:\tlearn: 0.0435560\ttotal: 3.54s\tremaining: 266ms\n",
            "93:\tlearn: 0.0432894\ttotal: 3.57s\tremaining: 228ms\n",
            "94:\tlearn: 0.0429256\ttotal: 3.61s\tremaining: 190ms\n",
            "95:\tlearn: 0.0426763\ttotal: 3.67s\tremaining: 153ms\n",
            "96:\tlearn: 0.0424429\ttotal: 3.71s\tremaining: 115ms\n",
            "97:\tlearn: 0.0420697\ttotal: 3.74s\tremaining: 76.4ms\n",
            "98:\tlearn: 0.0417679\ttotal: 3.78s\tremaining: 38.2ms\n",
            "99:\tlearn: 0.0413593\ttotal: 3.82s\tremaining: 0us\n",
            "0:\tlearn: 0.5622535\ttotal: 47.9ms\tremaining: 4.74s\n",
            "1:\tlearn: 0.4733857\ttotal: 96ms\tremaining: 4.71s\n",
            "2:\tlearn: 0.4154796\ttotal: 141ms\tremaining: 4.57s\n",
            "3:\tlearn: 0.3693039\ttotal: 187ms\tremaining: 4.5s\n",
            "4:\tlearn: 0.3379965\ttotal: 235ms\tremaining: 4.46s\n",
            "5:\tlearn: 0.3116648\ttotal: 285ms\tremaining: 4.46s\n",
            "6:\tlearn: 0.2896457\ttotal: 334ms\tremaining: 4.44s\n",
            "7:\tlearn: 0.2576306\ttotal: 382ms\tremaining: 4.39s\n",
            "8:\tlearn: 0.2434597\ttotal: 434ms\tremaining: 4.39s\n",
            "9:\tlearn: 0.2267681\ttotal: 486ms\tremaining: 4.37s\n",
            "10:\tlearn: 0.2155838\ttotal: 582ms\tremaining: 4.71s\n",
            "11:\tlearn: 0.2068216\ttotal: 633ms\tremaining: 4.64s\n",
            "12:\tlearn: 0.1983358\ttotal: 685ms\tremaining: 4.58s\n",
            "13:\tlearn: 0.1881697\ttotal: 735ms\tremaining: 4.51s\n",
            "14:\tlearn: 0.1807015\ttotal: 800ms\tremaining: 4.53s\n",
            "15:\tlearn: 0.1736311\ttotal: 849ms\tremaining: 4.46s\n",
            "16:\tlearn: 0.1650524\ttotal: 894ms\tremaining: 4.37s\n",
            "17:\tlearn: 0.1603066\ttotal: 943ms\tremaining: 4.29s\n",
            "18:\tlearn: 0.1551981\ttotal: 990ms\tremaining: 4.22s\n",
            "19:\tlearn: 0.1511528\ttotal: 1.05s\tremaining: 4.19s\n",
            "20:\tlearn: 0.1469693\ttotal: 1.09s\tremaining: 4.12s\n",
            "21:\tlearn: 0.1419236\ttotal: 1.15s\tremaining: 4.08s\n",
            "22:\tlearn: 0.1376548\ttotal: 1.23s\tremaining: 4.11s\n",
            "23:\tlearn: 0.1336337\ttotal: 1.28s\tremaining: 4.05s\n",
            "24:\tlearn: 0.1302886\ttotal: 1.32s\tremaining: 3.97s\n",
            "25:\tlearn: 0.1277091\ttotal: 1.37s\tremaining: 3.89s\n",
            "26:\tlearn: 0.1242127\ttotal: 1.41s\tremaining: 3.81s\n",
            "27:\tlearn: 0.1209355\ttotal: 1.46s\tremaining: 3.74s\n",
            "28:\tlearn: 0.1180369\ttotal: 1.49s\tremaining: 3.66s\n",
            "29:\tlearn: 0.1145741\ttotal: 1.53s\tremaining: 3.57s\n",
            "30:\tlearn: 0.1121165\ttotal: 1.58s\tremaining: 3.52s\n",
            "31:\tlearn: 0.1074980\ttotal: 1.64s\tremaining: 3.47s\n",
            "32:\tlearn: 0.1054487\ttotal: 1.68s\tremaining: 3.4s\n",
            "33:\tlearn: 0.1038161\ttotal: 1.71s\tremaining: 3.32s\n",
            "34:\tlearn: 0.1006287\ttotal: 1.74s\tremaining: 3.24s\n",
            "35:\tlearn: 0.0980578\ttotal: 1.78s\tremaining: 3.16s\n",
            "36:\tlearn: 0.0960728\ttotal: 1.81s\tremaining: 3.09s\n",
            "37:\tlearn: 0.0942938\ttotal: 1.85s\tremaining: 3.01s\n",
            "38:\tlearn: 0.0921085\ttotal: 1.89s\tremaining: 2.96s\n",
            "39:\tlearn: 0.0904968\ttotal: 1.93s\tremaining: 2.9s\n",
            "40:\tlearn: 0.0890239\ttotal: 1.97s\tremaining: 2.83s\n",
            "41:\tlearn: 0.0871884\ttotal: 2s\tremaining: 2.76s\n",
            "42:\tlearn: 0.0857656\ttotal: 2.03s\tremaining: 2.7s\n",
            "43:\tlearn: 0.0845843\ttotal: 2.08s\tremaining: 2.64s\n",
            "44:\tlearn: 0.0829243\ttotal: 2.11s\tremaining: 2.58s\n",
            "45:\tlearn: 0.0811386\ttotal: 2.15s\tremaining: 2.52s\n",
            "46:\tlearn: 0.0800870\ttotal: 2.18s\tremaining: 2.46s\n",
            "47:\tlearn: 0.0786165\ttotal: 2.22s\tremaining: 2.4s\n",
            "48:\tlearn: 0.0775348\ttotal: 2.25s\tremaining: 2.34s\n",
            "49:\tlearn: 0.0764935\ttotal: 2.29s\tremaining: 2.29s\n",
            "50:\tlearn: 0.0751549\ttotal: 2.33s\tremaining: 2.23s\n",
            "51:\tlearn: 0.0742692\ttotal: 2.36s\tremaining: 2.18s\n",
            "52:\tlearn: 0.0733831\ttotal: 2.4s\tremaining: 2.13s\n",
            "53:\tlearn: 0.0723226\ttotal: 2.43s\tremaining: 2.07s\n",
            "54:\tlearn: 0.0716556\ttotal: 2.47s\tremaining: 2.02s\n",
            "55:\tlearn: 0.0708096\ttotal: 2.5s\tremaining: 1.97s\n",
            "56:\tlearn: 0.0700669\ttotal: 2.54s\tremaining: 1.92s\n",
            "57:\tlearn: 0.0693523\ttotal: 2.58s\tremaining: 1.87s\n",
            "58:\tlearn: 0.0683792\ttotal: 2.61s\tremaining: 1.81s\n",
            "59:\tlearn: 0.0674215\ttotal: 2.68s\tremaining: 1.78s\n",
            "60:\tlearn: 0.0668026\ttotal: 2.71s\tremaining: 1.73s\n",
            "61:\tlearn: 0.0659720\ttotal: 2.75s\tremaining: 1.68s\n",
            "62:\tlearn: 0.0650637\ttotal: 2.79s\tremaining: 1.64s\n",
            "63:\tlearn: 0.0640931\ttotal: 2.82s\tremaining: 1.58s\n",
            "64:\tlearn: 0.0633558\ttotal: 2.86s\tremaining: 1.54s\n",
            "65:\tlearn: 0.0620561\ttotal: 2.91s\tremaining: 1.5s\n",
            "66:\tlearn: 0.0613091\ttotal: 2.95s\tremaining: 1.45s\n",
            "67:\tlearn: 0.0606097\ttotal: 2.99s\tremaining: 1.41s\n",
            "68:\tlearn: 0.0600436\ttotal: 3.03s\tremaining: 1.36s\n",
            "69:\tlearn: 0.0591447\ttotal: 3.08s\tremaining: 1.32s\n",
            "70:\tlearn: 0.0584148\ttotal: 3.12s\tremaining: 1.27s\n",
            "71:\tlearn: 0.0577634\ttotal: 3.16s\tremaining: 1.23s\n",
            "72:\tlearn: 0.0561512\ttotal: 3.2s\tremaining: 1.19s\n",
            "73:\tlearn: 0.0555950\ttotal: 3.24s\tremaining: 1.14s\n",
            "74:\tlearn: 0.0553209\ttotal: 3.28s\tremaining: 1.09s\n",
            "75:\tlearn: 0.0548510\ttotal: 3.31s\tremaining: 1.05s\n",
            "76:\tlearn: 0.0541999\ttotal: 3.35s\tremaining: 1s\n",
            "77:\tlearn: 0.0537742\ttotal: 3.38s\tremaining: 955ms\n",
            "78:\tlearn: 0.0532887\ttotal: 3.42s\tremaining: 910ms\n",
            "79:\tlearn: 0.0527234\ttotal: 3.46s\tremaining: 864ms\n",
            "80:\tlearn: 0.0522043\ttotal: 3.51s\tremaining: 823ms\n",
            "81:\tlearn: 0.0517392\ttotal: 3.54s\tremaining: 778ms\n",
            "82:\tlearn: 0.0513603\ttotal: 3.58s\tremaining: 733ms\n",
            "83:\tlearn: 0.0507754\ttotal: 3.61s\tremaining: 688ms\n",
            "84:\tlearn: 0.0501143\ttotal: 3.65s\tremaining: 644ms\n",
            "85:\tlearn: 0.0496499\ttotal: 3.69s\tremaining: 601ms\n",
            "86:\tlearn: 0.0492481\ttotal: 3.75s\tremaining: 560ms\n",
            "87:\tlearn: 0.0489065\ttotal: 3.78s\tremaining: 516ms\n",
            "88:\tlearn: 0.0484411\ttotal: 3.82s\tremaining: 472ms\n",
            "89:\tlearn: 0.0480482\ttotal: 3.85s\tremaining: 428ms\n",
            "90:\tlearn: 0.0477819\ttotal: 3.89s\tremaining: 384ms\n",
            "91:\tlearn: 0.0474787\ttotal: 3.92s\tremaining: 341ms\n",
            "92:\tlearn: 0.0468550\ttotal: 3.96s\tremaining: 298ms\n",
            "93:\tlearn: 0.0464197\ttotal: 3.99s\tremaining: 255ms\n",
            "94:\tlearn: 0.0459895\ttotal: 4.03s\tremaining: 212ms\n",
            "95:\tlearn: 0.0455893\ttotal: 4.06s\tremaining: 169ms\n",
            "96:\tlearn: 0.0452155\ttotal: 4.1s\tremaining: 127ms\n",
            "97:\tlearn: 0.0448261\ttotal: 4.13s\tremaining: 84.3ms\n",
            "98:\tlearn: 0.0443965\ttotal: 4.17s\tremaining: 42.1ms\n",
            "99:\tlearn: 0.0440975\ttotal: 4.2s\tremaining: 0us\n",
            "0:\tlearn: 0.5662980\ttotal: 37.6ms\tremaining: 3.72s\n",
            "1:\tlearn: 0.4770177\ttotal: 77.8ms\tremaining: 3.81s\n",
            "2:\tlearn: 0.4140206\ttotal: 113ms\tremaining: 3.66s\n",
            "3:\tlearn: 0.3698025\ttotal: 148ms\tremaining: 3.55s\n",
            "4:\tlearn: 0.3299125\ttotal: 191ms\tremaining: 3.63s\n",
            "5:\tlearn: 0.3079500\ttotal: 254ms\tremaining: 3.99s\n",
            "6:\tlearn: 0.2759162\ttotal: 289ms\tremaining: 3.84s\n",
            "7:\tlearn: 0.2580841\ttotal: 324ms\tremaining: 3.73s\n",
            "8:\tlearn: 0.2397004\ttotal: 359ms\tremaining: 3.63s\n",
            "9:\tlearn: 0.2278998\ttotal: 411ms\tremaining: 3.69s\n",
            "10:\tlearn: 0.2123994\ttotal: 447ms\tremaining: 3.62s\n",
            "11:\tlearn: 0.2017794\ttotal: 483ms\tremaining: 3.54s\n",
            "12:\tlearn: 0.1925150\ttotal: 516ms\tremaining: 3.45s\n",
            "13:\tlearn: 0.1850299\ttotal: 552ms\tremaining: 3.39s\n",
            "14:\tlearn: 0.1793760\ttotal: 589ms\tremaining: 3.34s\n",
            "15:\tlearn: 0.1720377\ttotal: 625ms\tremaining: 3.28s\n",
            "16:\tlearn: 0.1651587\ttotal: 661ms\tremaining: 3.23s\n",
            "17:\tlearn: 0.1594051\ttotal: 706ms\tremaining: 3.21s\n",
            "18:\tlearn: 0.1539553\ttotal: 749ms\tremaining: 3.19s\n",
            "19:\tlearn: 0.1481997\ttotal: 793ms\tremaining: 3.17s\n",
            "20:\tlearn: 0.1439583\ttotal: 833ms\tremaining: 3.13s\n",
            "21:\tlearn: 0.1384344\ttotal: 877ms\tremaining: 3.11s\n",
            "22:\tlearn: 0.1348847\ttotal: 921ms\tremaining: 3.08s\n",
            "23:\tlearn: 0.1313764\ttotal: 963ms\tremaining: 3.05s\n",
            "24:\tlearn: 0.1272352\ttotal: 1s\tremaining: 3.02s\n",
            "25:\tlearn: 0.1235969\ttotal: 1.04s\tremaining: 2.97s\n",
            "26:\tlearn: 0.1198535\ttotal: 1.08s\tremaining: 2.92s\n",
            "27:\tlearn: 0.1170157\ttotal: 1.12s\tremaining: 2.87s\n",
            "28:\tlearn: 0.1146290\ttotal: 1.15s\tremaining: 2.82s\n",
            "29:\tlearn: 0.1125094\ttotal: 1.19s\tremaining: 2.77s\n",
            "30:\tlearn: 0.1108603\ttotal: 1.22s\tremaining: 2.72s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31:\tlearn: 0.1085740\ttotal: 1.28s\tremaining: 2.71s\n",
            "32:\tlearn: 0.1054041\ttotal: 1.32s\tremaining: 2.69s\n",
            "33:\tlearn: 0.1012448\ttotal: 1.36s\tremaining: 2.64s\n",
            "34:\tlearn: 0.0996823\ttotal: 1.39s\tremaining: 2.59s\n",
            "35:\tlearn: 0.0973463\ttotal: 1.43s\tremaining: 2.55s\n",
            "36:\tlearn: 0.0957952\ttotal: 1.47s\tremaining: 2.5s\n",
            "37:\tlearn: 0.0940349\ttotal: 1.51s\tremaining: 2.46s\n",
            "38:\tlearn: 0.0922334\ttotal: 1.54s\tremaining: 2.41s\n",
            "39:\tlearn: 0.0902531\ttotal: 1.58s\tremaining: 2.37s\n",
            "40:\tlearn: 0.0883961\ttotal: 1.62s\tremaining: 2.33s\n",
            "41:\tlearn: 0.0871011\ttotal: 1.66s\tremaining: 2.29s\n",
            "42:\tlearn: 0.0857308\ttotal: 1.69s\tremaining: 2.24s\n",
            "43:\tlearn: 0.0844851\ttotal: 1.73s\tremaining: 2.2s\n",
            "44:\tlearn: 0.0830916\ttotal: 1.76s\tremaining: 2.15s\n",
            "45:\tlearn: 0.0815318\ttotal: 1.8s\tremaining: 2.11s\n",
            "46:\tlearn: 0.0807083\ttotal: 1.83s\tremaining: 2.06s\n",
            "47:\tlearn: 0.0794048\ttotal: 1.87s\tremaining: 2.02s\n",
            "48:\tlearn: 0.0780138\ttotal: 1.9s\tremaining: 1.98s\n",
            "49:\tlearn: 0.0768372\ttotal: 1.94s\tremaining: 1.94s\n",
            "50:\tlearn: 0.0757096\ttotal: 1.97s\tremaining: 1.9s\n",
            "51:\tlearn: 0.0745122\ttotal: 2.01s\tremaining: 1.85s\n",
            "52:\tlearn: 0.0736222\ttotal: 2.05s\tremaining: 1.82s\n",
            "53:\tlearn: 0.0723639\ttotal: 2.08s\tremaining: 1.77s\n",
            "54:\tlearn: 0.0714154\ttotal: 2.12s\tremaining: 1.73s\n",
            "55:\tlearn: 0.0708173\ttotal: 2.15s\tremaining: 1.69s\n",
            "56:\tlearn: 0.0698589\ttotal: 2.19s\tremaining: 1.65s\n",
            "57:\tlearn: 0.0689420\ttotal: 2.22s\tremaining: 1.61s\n",
            "58:\tlearn: 0.0680940\ttotal: 2.27s\tremaining: 1.57s\n",
            "59:\tlearn: 0.0671970\ttotal: 2.31s\tremaining: 1.54s\n",
            "60:\tlearn: 0.0667402\ttotal: 2.37s\tremaining: 1.51s\n",
            "61:\tlearn: 0.0659991\ttotal: 2.42s\tremaining: 1.48s\n",
            "62:\tlearn: 0.0653859\ttotal: 2.46s\tremaining: 1.45s\n",
            "63:\tlearn: 0.0645826\ttotal: 2.5s\tremaining: 1.41s\n",
            "64:\tlearn: 0.0638698\ttotal: 2.53s\tremaining: 1.36s\n",
            "65:\tlearn: 0.0628107\ttotal: 2.57s\tremaining: 1.32s\n",
            "66:\tlearn: 0.0620768\ttotal: 2.61s\tremaining: 1.28s\n",
            "67:\tlearn: 0.0614351\ttotal: 2.64s\tremaining: 1.24s\n",
            "68:\tlearn: 0.0607134\ttotal: 2.67s\tremaining: 1.2s\n",
            "69:\tlearn: 0.0598927\ttotal: 2.71s\tremaining: 1.16s\n",
            "70:\tlearn: 0.0590266\ttotal: 2.76s\tremaining: 1.13s\n",
            "71:\tlearn: 0.0583838\ttotal: 2.8s\tremaining: 1.09s\n",
            "72:\tlearn: 0.0569896\ttotal: 2.83s\tremaining: 1.05s\n",
            "73:\tlearn: 0.0562404\ttotal: 2.87s\tremaining: 1.01s\n",
            "74:\tlearn: 0.0558587\ttotal: 2.9s\tremaining: 968ms\n",
            "75:\tlearn: 0.0554013\ttotal: 2.94s\tremaining: 928ms\n",
            "76:\tlearn: 0.0549155\ttotal: 2.97s\tremaining: 888ms\n",
            "77:\tlearn: 0.0545861\ttotal: 3s\tremaining: 847ms\n",
            "78:\tlearn: 0.0539008\ttotal: 3.04s\tremaining: 808ms\n",
            "79:\tlearn: 0.0532291\ttotal: 3.1s\tremaining: 774ms\n",
            "80:\tlearn: 0.0525965\ttotal: 3.14s\tremaining: 736ms\n",
            "81:\tlearn: 0.0521745\ttotal: 3.18s\tremaining: 698ms\n",
            "82:\tlearn: 0.0516539\ttotal: 3.22s\tremaining: 659ms\n",
            "83:\tlearn: 0.0513119\ttotal: 3.26s\tremaining: 621ms\n",
            "84:\tlearn: 0.0507713\ttotal: 3.31s\tremaining: 583ms\n",
            "85:\tlearn: 0.0500263\ttotal: 3.35s\tremaining: 545ms\n",
            "86:\tlearn: 0.0495223\ttotal: 3.4s\tremaining: 508ms\n",
            "87:\tlearn: 0.0491736\ttotal: 3.48s\tremaining: 474ms\n",
            "88:\tlearn: 0.0485261\ttotal: 3.52s\tremaining: 435ms\n",
            "89:\tlearn: 0.0481992\ttotal: 3.55s\tremaining: 395ms\n",
            "90:\tlearn: 0.0476745\ttotal: 3.6s\tremaining: 356ms\n",
            "91:\tlearn: 0.0472850\ttotal: 3.63s\tremaining: 316ms\n",
            "92:\tlearn: 0.0468268\ttotal: 3.68s\tremaining: 277ms\n",
            "93:\tlearn: 0.0460603\ttotal: 3.71s\tremaining: 237ms\n",
            "94:\tlearn: 0.0456853\ttotal: 3.75s\tremaining: 197ms\n",
            "95:\tlearn: 0.0452525\ttotal: 3.78s\tremaining: 158ms\n",
            "96:\tlearn: 0.0449727\ttotal: 3.82s\tremaining: 118ms\n",
            "97:\tlearn: 0.0445417\ttotal: 3.85s\tremaining: 78.6ms\n",
            "98:\tlearn: 0.0441388\ttotal: 3.89s\tremaining: 39.3ms\n",
            "99:\tlearn: 0.0437460\ttotal: 3.93s\tremaining: 0us\n",
            "0:\tlearn: 0.5671726\ttotal: 41.7ms\tremaining: 4.13s\n",
            "1:\tlearn: 0.4785239\ttotal: 93.7ms\tremaining: 4.59s\n",
            "2:\tlearn: 0.4101886\ttotal: 130ms\tremaining: 4.21s\n",
            "3:\tlearn: 0.3702145\ttotal: 167ms\tremaining: 4.01s\n",
            "4:\tlearn: 0.3335022\ttotal: 232ms\tremaining: 4.4s\n",
            "5:\tlearn: 0.3058937\ttotal: 273ms\tremaining: 4.27s\n",
            "6:\tlearn: 0.2827913\ttotal: 307ms\tremaining: 4.08s\n",
            "7:\tlearn: 0.2626006\ttotal: 343ms\tremaining: 3.95s\n",
            "8:\tlearn: 0.2391318\ttotal: 390ms\tremaining: 3.95s\n",
            "9:\tlearn: 0.2254503\ttotal: 428ms\tremaining: 3.85s\n",
            "10:\tlearn: 0.2148062\ttotal: 460ms\tremaining: 3.73s\n",
            "11:\tlearn: 0.2024549\ttotal: 496ms\tremaining: 3.64s\n",
            "12:\tlearn: 0.1951972\ttotal: 532ms\tremaining: 3.56s\n",
            "13:\tlearn: 0.1881182\ttotal: 569ms\tremaining: 3.5s\n",
            "14:\tlearn: 0.1814351\ttotal: 606ms\tremaining: 3.43s\n",
            "15:\tlearn: 0.1736112\ttotal: 640ms\tremaining: 3.36s\n",
            "16:\tlearn: 0.1656671\ttotal: 676ms\tremaining: 3.3s\n",
            "17:\tlearn: 0.1593015\ttotal: 712ms\tremaining: 3.24s\n",
            "18:\tlearn: 0.1544140\ttotal: 747ms\tremaining: 3.19s\n",
            "19:\tlearn: 0.1500542\ttotal: 783ms\tremaining: 3.13s\n",
            "20:\tlearn: 0.1452460\ttotal: 816ms\tremaining: 3.07s\n",
            "21:\tlearn: 0.1407609\ttotal: 849ms\tremaining: 3.01s\n",
            "22:\tlearn: 0.1367958\ttotal: 886ms\tremaining: 2.96s\n",
            "23:\tlearn: 0.1325031\ttotal: 922ms\tremaining: 2.92s\n",
            "24:\tlearn: 0.1288438\ttotal: 958ms\tremaining: 2.87s\n",
            "25:\tlearn: 0.1250441\ttotal: 994ms\tremaining: 2.83s\n",
            "26:\tlearn: 0.1221006\ttotal: 1.03s\tremaining: 2.78s\n",
            "27:\tlearn: 0.1189958\ttotal: 1.07s\tremaining: 2.74s\n",
            "28:\tlearn: 0.1166869\ttotal: 1.1s\tremaining: 2.69s\n",
            "29:\tlearn: 0.1137236\ttotal: 1.14s\tremaining: 2.65s\n",
            "30:\tlearn: 0.1117880\ttotal: 1.17s\tremaining: 2.61s\n",
            "31:\tlearn: 0.1096014\ttotal: 1.22s\tremaining: 2.6s\n",
            "32:\tlearn: 0.1071709\ttotal: 1.29s\tremaining: 2.63s\n",
            "33:\tlearn: 0.1051197\ttotal: 1.34s\tremaining: 2.6s\n",
            "34:\tlearn: 0.1031483\ttotal: 1.38s\tremaining: 2.56s\n",
            "35:\tlearn: 0.1013214\ttotal: 1.42s\tremaining: 2.52s\n",
            "36:\tlearn: 0.0997989\ttotal: 1.46s\tremaining: 2.49s\n",
            "37:\tlearn: 0.0979837\ttotal: 1.51s\tremaining: 2.46s\n",
            "38:\tlearn: 0.0962085\ttotal: 1.55s\tremaining: 2.42s\n",
            "39:\tlearn: 0.0946358\ttotal: 1.59s\tremaining: 2.39s\n",
            "40:\tlearn: 0.0923100\ttotal: 1.64s\tremaining: 2.35s\n",
            "41:\tlearn: 0.0904826\ttotal: 1.68s\tremaining: 2.32s\n",
            "42:\tlearn: 0.0869639\ttotal: 1.72s\tremaining: 2.28s\n",
            "43:\tlearn: 0.0851444\ttotal: 1.75s\tremaining: 2.23s\n",
            "44:\tlearn: 0.0836406\ttotal: 1.79s\tremaining: 2.18s\n",
            "45:\tlearn: 0.0826543\ttotal: 1.82s\tremaining: 2.14s\n",
            "46:\tlearn: 0.0815740\ttotal: 1.85s\tremaining: 2.09s\n",
            "47:\tlearn: 0.0805188\ttotal: 1.89s\tremaining: 2.05s\n",
            "48:\tlearn: 0.0794369\ttotal: 1.92s\tremaining: 2s\n",
            "49:\tlearn: 0.0784343\ttotal: 1.96s\tremaining: 1.96s\n",
            "50:\tlearn: 0.0774348\ttotal: 1.99s\tremaining: 1.91s\n",
            "51:\tlearn: 0.0763931\ttotal: 2.03s\tremaining: 1.87s\n",
            "52:\tlearn: 0.0753507\ttotal: 2.06s\tremaining: 1.83s\n",
            "53:\tlearn: 0.0742844\ttotal: 2.1s\tremaining: 1.79s\n",
            "54:\tlearn: 0.0733280\ttotal: 2.13s\tremaining: 1.75s\n",
            "55:\tlearn: 0.0721906\ttotal: 2.17s\tremaining: 1.7s\n",
            "56:\tlearn: 0.0714138\ttotal: 2.21s\tremaining: 1.66s\n",
            "57:\tlearn: 0.0703927\ttotal: 2.24s\tremaining: 1.62s\n",
            "58:\tlearn: 0.0698586\ttotal: 2.27s\tremaining: 1.58s\n",
            "59:\tlearn: 0.0691528\ttotal: 2.31s\tremaining: 1.54s\n",
            "60:\tlearn: 0.0679808\ttotal: 2.38s\tremaining: 1.52s\n",
            "61:\tlearn: 0.0670722\ttotal: 2.41s\tremaining: 1.48s\n",
            "62:\tlearn: 0.0660606\ttotal: 2.45s\tremaining: 1.44s\n",
            "63:\tlearn: 0.0653202\ttotal: 2.48s\tremaining: 1.4s\n",
            "64:\tlearn: 0.0646835\ttotal: 2.52s\tremaining: 1.36s\n",
            "65:\tlearn: 0.0639377\ttotal: 2.55s\tremaining: 1.31s\n",
            "66:\tlearn: 0.0632695\ttotal: 2.59s\tremaining: 1.27s\n",
            "67:\tlearn: 0.0624491\ttotal: 2.63s\tremaining: 1.24s\n",
            "68:\tlearn: 0.0614327\ttotal: 2.66s\tremaining: 1.19s\n",
            "69:\tlearn: 0.0607591\ttotal: 2.69s\tremaining: 1.15s\n",
            "70:\tlearn: 0.0597743\ttotal: 2.73s\tremaining: 1.11s\n",
            "71:\tlearn: 0.0590178\ttotal: 2.77s\tremaining: 1.08s\n",
            "72:\tlearn: 0.0583932\ttotal: 2.8s\tremaining: 1.04s\n",
            "73:\tlearn: 0.0576930\ttotal: 2.84s\tremaining: 998ms\n",
            "74:\tlearn: 0.0572222\ttotal: 2.87s\tremaining: 958ms\n",
            "75:\tlearn: 0.0564593\ttotal: 2.91s\tremaining: 919ms\n",
            "76:\tlearn: 0.0558250\ttotal: 2.94s\tremaining: 880ms\n",
            "77:\tlearn: 0.0546752\ttotal: 2.98s\tremaining: 840ms\n",
            "78:\tlearn: 0.0540201\ttotal: 3.03s\tremaining: 805ms\n",
            "79:\tlearn: 0.0535743\ttotal: 3.06s\tremaining: 766ms\n",
            "80:\tlearn: 0.0530283\ttotal: 3.09s\tremaining: 726ms\n",
            "81:\tlearn: 0.0526309\ttotal: 3.13s\tremaining: 687ms\n",
            "82:\tlearn: 0.0522274\ttotal: 3.16s\tremaining: 648ms\n",
            "83:\tlearn: 0.0516678\ttotal: 3.2s\tremaining: 609ms\n",
            "84:\tlearn: 0.0510157\ttotal: 3.23s\tremaining: 571ms\n",
            "85:\tlearn: 0.0503145\ttotal: 3.26s\tremaining: 531ms\n",
            "86:\tlearn: 0.0498657\ttotal: 3.3s\tremaining: 493ms\n",
            "87:\tlearn: 0.0495699\ttotal: 3.33s\tremaining: 454ms\n",
            "88:\tlearn: 0.0490845\ttotal: 3.36s\tremaining: 416ms\n",
            "89:\tlearn: 0.0486965\ttotal: 3.42s\tremaining: 380ms\n",
            "90:\tlearn: 0.0482928\ttotal: 3.47s\tremaining: 343ms\n",
            "91:\tlearn: 0.0478781\ttotal: 3.5s\tremaining: 305ms\n",
            "92:\tlearn: 0.0475319\ttotal: 3.54s\tremaining: 266ms\n",
            "93:\tlearn: 0.0469674\ttotal: 3.58s\tremaining: 228ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94:\tlearn: 0.0466143\ttotal: 3.63s\tremaining: 191ms\n",
            "95:\tlearn: 0.0461649\ttotal: 3.66s\tremaining: 153ms\n",
            "96:\tlearn: 0.0459347\ttotal: 3.7s\tremaining: 114ms\n",
            "97:\tlearn: 0.0456282\ttotal: 3.74s\tremaining: 76.4ms\n",
            "98:\tlearn: 0.0453239\ttotal: 3.78s\tremaining: 38.2ms\n",
            "99:\tlearn: 0.0450078\ttotal: 3.83s\tremaining: 0us\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:47:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:47:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:48:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:48:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:49:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 71514, number of negative: 71513\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1852\n",
            "[LightGBM] [Info] Number of data points in the train set: 143027, number of used features: 41\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000014\n",
            "[LightGBM] [Info] Start training from score 0.000014\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 71514, number of negative: 71513\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1851\n",
            "[LightGBM] [Info] Number of data points in the train set: 143027, number of used features: 41\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000014\n",
            "[LightGBM] [Info] Start training from score 0.000014\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 71513, number of negative: 71514\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069710 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1852\n",
            "[LightGBM] [Info] Number of data points in the train set: 143027, number of used features: 41\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000014\n",
            "[LightGBM] [Info] Start training from score -0.000014\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 71513, number of negative: 71514\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076716 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1851\n",
            "[LightGBM] [Info] Number of data points in the train set: 143027, number of used features: 41\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000014\n",
            "[LightGBM] [Info] Start training from score -0.000014\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 71514, number of negative: 71514\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064342 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1851\n",
            "[LightGBM] [Info] Number of data points in the train set: 143028, number of used features: 41\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:477: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:477: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:477: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:477: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\satya_omijkxl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6045113\ttotal: 23.5ms\tremaining: 2.32s\n",
            "1:\tlearn: 0.5309393\ttotal: 44.4ms\tremaining: 2.18s\n",
            "2:\tlearn: 0.4702016\ttotal: 64.9ms\tremaining: 2.1s\n",
            "3:\tlearn: 0.4176977\ttotal: 86.6ms\tremaining: 2.08s\n",
            "4:\tlearn: 0.3734107\ttotal: 108ms\tremaining: 2.06s\n",
            "5:\tlearn: 0.3352420\ttotal: 129ms\tremaining: 2.03s\n",
            "6:\tlearn: 0.3024606\ttotal: 149ms\tremaining: 1.98s\n",
            "7:\tlearn: 0.2732398\ttotal: 173ms\tremaining: 1.99s\n",
            "8:\tlearn: 0.2475498\ttotal: 194ms\tremaining: 1.96s\n",
            "9:\tlearn: 0.2252782\ttotal: 214ms\tremaining: 1.92s\n",
            "10:\tlearn: 0.2054021\ttotal: 237ms\tremaining: 1.91s\n",
            "11:\tlearn: 0.1878945\ttotal: 259ms\tremaining: 1.9s\n",
            "12:\tlearn: 0.1723287\ttotal: 279ms\tremaining: 1.87s\n",
            "13:\tlearn: 0.1587864\ttotal: 300ms\tremaining: 1.84s\n",
            "14:\tlearn: 0.1463082\ttotal: 320ms\tremaining: 1.81s\n",
            "15:\tlearn: 0.1356432\ttotal: 341ms\tremaining: 1.79s\n",
            "16:\tlearn: 0.1259917\ttotal: 365ms\tremaining: 1.78s\n",
            "17:\tlearn: 0.1173335\ttotal: 386ms\tremaining: 1.76s\n",
            "18:\tlearn: 0.1097472\ttotal: 407ms\tremaining: 1.73s\n",
            "19:\tlearn: 0.1028233\ttotal: 431ms\tremaining: 1.72s\n",
            "20:\tlearn: 0.0965258\ttotal: 453ms\tremaining: 1.7s\n",
            "21:\tlearn: 0.0910716\ttotal: 474ms\tremaining: 1.68s\n",
            "22:\tlearn: 0.0859543\ttotal: 503ms\tremaining: 1.69s\n",
            "23:\tlearn: 0.0814015\ttotal: 523ms\tremaining: 1.66s\n",
            "24:\tlearn: 0.0772522\ttotal: 544ms\tremaining: 1.63s\n",
            "25:\tlearn: 0.0737092\ttotal: 565ms\tremaining: 1.61s\n",
            "26:\tlearn: 0.0702805\ttotal: 586ms\tremaining: 1.58s\n",
            "27:\tlearn: 0.0672359\ttotal: 609ms\tremaining: 1.57s\n",
            "28:\tlearn: 0.0646018\ttotal: 631ms\tremaining: 1.54s\n",
            "29:\tlearn: 0.0621485\ttotal: 653ms\tremaining: 1.52s\n",
            "30:\tlearn: 0.0598442\ttotal: 674ms\tremaining: 1.5s\n",
            "31:\tlearn: 0.0578967\ttotal: 696ms\tremaining: 1.48s\n",
            "32:\tlearn: 0.0561993\ttotal: 721ms\tremaining: 1.46s\n",
            "33:\tlearn: 0.0544561\ttotal: 769ms\tremaining: 1.49s\n",
            "34:\tlearn: 0.0530611\ttotal: 806ms\tremaining: 1.5s\n",
            "35:\tlearn: 0.0516991\ttotal: 832ms\tremaining: 1.48s\n",
            "36:\tlearn: 0.0505676\ttotal: 857ms\tremaining: 1.46s\n",
            "37:\tlearn: 0.0494591\ttotal: 883ms\tremaining: 1.44s\n",
            "38:\tlearn: 0.0485309\ttotal: 908ms\tremaining: 1.42s\n",
            "39:\tlearn: 0.0475697\ttotal: 933ms\tremaining: 1.4s\n",
            "40:\tlearn: 0.0467698\ttotal: 960ms\tremaining: 1.38s\n",
            "41:\tlearn: 0.0459326\ttotal: 989ms\tremaining: 1.36s\n",
            "42:\tlearn: 0.0451898\ttotal: 1.01s\tremaining: 1.34s\n",
            "43:\tlearn: 0.0444958\ttotal: 1.04s\tremaining: 1.32s\n",
            "44:\tlearn: 0.0439007\ttotal: 1.06s\tremaining: 1.3s\n",
            "45:\tlearn: 0.0434801\ttotal: 1.09s\tremaining: 1.28s\n",
            "46:\tlearn: 0.0429794\ttotal: 1.11s\tremaining: 1.26s\n",
            "47:\tlearn: 0.0426075\ttotal: 1.14s\tremaining: 1.23s\n",
            "48:\tlearn: 0.0421967\ttotal: 1.17s\tremaining: 1.21s\n",
            "49:\tlearn: 0.0418364\ttotal: 1.19s\tremaining: 1.19s\n",
            "50:\tlearn: 0.0414611\ttotal: 1.21s\tremaining: 1.16s\n",
            "51:\tlearn: 0.0412171\ttotal: 1.23s\tremaining: 1.14s\n",
            "52:\tlearn: 0.0409227\ttotal: 1.25s\tremaining: 1.11s\n",
            "53:\tlearn: 0.0406315\ttotal: 1.27s\tremaining: 1.08s\n",
            "54:\tlearn: 0.0404337\ttotal: 1.3s\tremaining: 1.06s\n",
            "55:\tlearn: 0.0401834\ttotal: 1.32s\tremaining: 1.03s\n",
            "56:\tlearn: 0.0399324\ttotal: 1.34s\tremaining: 1.01s\n",
            "57:\tlearn: 0.0397371\ttotal: 1.36s\tremaining: 988ms\n",
            "58:\tlearn: 0.0395827\ttotal: 1.38s\tremaining: 962ms\n",
            "59:\tlearn: 0.0394282\ttotal: 1.41s\tremaining: 937ms\n",
            "60:\tlearn: 0.0392192\ttotal: 1.43s\tremaining: 912ms\n",
            "61:\tlearn: 0.0390728\ttotal: 1.45s\tremaining: 887ms\n",
            "62:\tlearn: 0.0389443\ttotal: 1.47s\tremaining: 861ms\n",
            "63:\tlearn: 0.0388272\ttotal: 1.49s\tremaining: 837ms\n",
            "64:\tlearn: 0.0386699\ttotal: 1.51s\tremaining: 813ms\n",
            "65:\tlearn: 0.0384971\ttotal: 1.53s\tremaining: 788ms\n",
            "66:\tlearn: 0.0383537\ttotal: 1.55s\tremaining: 763ms\n",
            "67:\tlearn: 0.0382461\ttotal: 1.57s\tremaining: 739ms\n",
            "68:\tlearn: 0.0381354\ttotal: 1.59s\tremaining: 715ms\n",
            "69:\tlearn: 0.0380444\ttotal: 1.61s\tremaining: 691ms\n",
            "70:\tlearn: 0.0379181\ttotal: 1.63s\tremaining: 668ms\n",
            "71:\tlearn: 0.0378183\ttotal: 1.67s\tremaining: 648ms\n",
            "72:\tlearn: 0.0376884\ttotal: 1.69s\tremaining: 625ms\n",
            "73:\tlearn: 0.0376055\ttotal: 1.71s\tremaining: 601ms\n",
            "74:\tlearn: 0.0375505\ttotal: 1.73s\tremaining: 577ms\n",
            "75:\tlearn: 0.0374450\ttotal: 1.75s\tremaining: 553ms\n",
            "76:\tlearn: 0.0373257\ttotal: 1.78s\tremaining: 531ms\n",
            "77:\tlearn: 0.0372487\ttotal: 1.81s\tremaining: 511ms\n",
            "78:\tlearn: 0.0371701\ttotal: 1.84s\tremaining: 490ms\n",
            "79:\tlearn: 0.0371116\ttotal: 1.86s\tremaining: 466ms\n",
            "80:\tlearn: 0.0370164\ttotal: 1.89s\tremaining: 442ms\n",
            "81:\tlearn: 0.0369588\ttotal: 1.91s\tremaining: 419ms\n",
            "82:\tlearn: 0.0369200\ttotal: 1.93s\tremaining: 395ms\n",
            "83:\tlearn: 0.0368512\ttotal: 1.95s\tremaining: 371ms\n",
            "84:\tlearn: 0.0367698\ttotal: 1.97s\tremaining: 348ms\n",
            "85:\tlearn: 0.0366791\ttotal: 1.99s\tremaining: 324ms\n",
            "86:\tlearn: 0.0366209\ttotal: 2.01s\tremaining: 301ms\n",
            "87:\tlearn: 0.0365160\ttotal: 2.03s\tremaining: 277ms\n",
            "88:\tlearn: 0.0364591\ttotal: 2.06s\tremaining: 254ms\n",
            "89:\tlearn: 0.0364133\ttotal: 2.08s\tremaining: 231ms\n",
            "90:\tlearn: 0.0363324\ttotal: 2.1s\tremaining: 208ms\n",
            "91:\tlearn: 0.0362830\ttotal: 2.12s\tremaining: 184ms\n",
            "92:\tlearn: 0.0362538\ttotal: 2.14s\tremaining: 161ms\n",
            "93:\tlearn: 0.0361934\ttotal: 2.16s\tremaining: 138ms\n",
            "94:\tlearn: 0.0361547\ttotal: 2.18s\tremaining: 115ms\n",
            "95:\tlearn: 0.0360675\ttotal: 2.2s\tremaining: 91.9ms\n",
            "96:\tlearn: 0.0360285\ttotal: 2.23s\tremaining: 68.8ms\n",
            "97:\tlearn: 0.0359843\ttotal: 2.25s\tremaining: 45.9ms\n",
            "98:\tlearn: 0.0359661\ttotal: 2.27s\tremaining: 22.9ms\n",
            "99:\tlearn: 0.0359435\ttotal: 2.29s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "StackingClassifier(estimators=[('catboost',\n",
              "                                <catboost.core.CatBoostClassifier object at 0x000001F4599E9130>),\n",
              "                               ('xgboost',\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              colsample_bylevel=None,\n",
              "                                              colsample_bynode=None,\n",
              "                                              colsample_bytree=None,\n",
              "                                              enable_categorical=False,\n",
              "                                              gamma=None, gpu_id=None,\n",
              "                                              importance_type=None,\n",
              "                                              interaction_constraints=None,\n",
              "                                              learning_rate=0.1,\n",
              "                                              max_delt...\n",
              "                                              predictor=None, random_state=42,\n",
              "                                              reg_alpha=None, reg_lambda=None,\n",
              "                                              scale_pos_weight=None,\n",
              "                                              subsample=None, tree_method=None,\n",
              "                                              validate_parameters=None,\n",
              "                                              verbosity=None)),\n",
              "                               ('lightgbm',\n",
              "                                LGBMClassifier(n_jobs=1, random_state=42)),\n",
              "                               ('Logistic',\n",
              "                                LogisticRegression(penalty='none',\n",
              "                                                   solver='newton-cg'))],\n",
              "                   final_estimator=<catboost.core.CatBoostClassifier object at 0x000001F45B876520>)"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stacking_model.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHR0JfevluJd"
      },
      "outputs": [],
      "source": [
        "y_pred = stacking_model.predict(X_test)\n",
        "y_train_predict = stacking_model.predict(X_train_resampled)\n",
        "\n",
        "print(\"Accuracy Score of Model1_train : \", accuracy_score(y_train_resampled,y_train_predict))\n",
        "print(\"Accuracy Score of Model1_test : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfNrykkXluJe"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('--'*50)\n",
        "print(classification_report(y_train_resampled, y_train_predict))\n",
        "print(confusion_matrix(y_train_resampled, y_train_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "g91LLCnlluJe",
        "outputId": "31627f9f-d7eb-4135-9a3d-d0dce92ea193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66.0 defaults\n"
          ]
        }
      ],
      "source": [
        "result = stacking_model.predict(X_test)\n",
        "print(f'{sum(result)} defaults')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkgCdTYbluJe"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame()\n",
        "results['ID'] = test.ID\n",
        "results['My prediction'] = result\n",
        "results['Real result'] = y_test\n",
        "results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7HKDDV3luJe",
        "outputId": "3b16f208-af73-4a2b-e0ea-5d45046da78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38401 from 38405 observations were predicted right\n"
          ]
        }
      ],
      "source": [
        "share_of_wrong_predicted = results[['My prediction', 'Real result']].duplicated().sum()\n",
        "print(f'{share_of_wrong_predicted} from {results.shape[0]} observations were predicted right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_nlQoGDluJf"
      },
      "outputs": [],
      "source": [
        "results.to_csv('res.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}